{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis workflow for the study \"Pairs of amino acids at the P- and A-sites of the ribosome predictably and causally modulate translation-elongation rates\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of data used in this study\n",
    "\n",
    "1. Jan, C. H., Williams, C. C., & Weissman, J. S. (2014). Principles of ER cotranslational translocation revealed by proximity-specific ribosome profiling. Science, 346(6210).\n",
    "\n",
    "2. Williams, C. C., Jan, C. H., & Weissman, J. S. (2014). Targeting and plasticity of mitochondrial proteins revealed by proximity-specific ribosome profiling. Science, 346(6210), 748-751.\n",
    "\n",
    "3. Young, D. J., Guydosh, N. R., Zhang, F., Hinnebusch, A. G., & Green, R. (2015). Rli1/ABCE1 recycles terminating ribosomes and controls translation reinitiation in 3′ UTRs in vivo. Cell, 162(4), 872-884.\n",
    "\n",
    "4. Weinberg, D. E., Shah, P., Eichhorn, S. W., Hussmann, J. A., Plotkin, J. B., & Bartel, D. P. (2016). Improved ribosome-footprint and mRNA measurements provide insights into dynamics and regulation of yeast translation. Cell reports, 14(7), 1787-1799.\n",
    "\n",
    "5. Nissley, D. A., Sharma, A. K., Ahmed, N., Friedrich, U. A., Kramer, G., Bukau, B., & O’Brien, E. P. (2016). Accurate prediction of cellular co-translational folding indicates proteins can switch from post-to co-translational folding. Nature communications, 7(1), 1-13.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to run the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pickle as Pickle\n",
    "from optparse import OptionParser\n",
    "import matplotlib.backends.backend_pdf as pdf\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib as mpl\n",
    "from matplotlib.table import Table\n",
    "import sys\n",
    "import statsmodels.sandbox.stats.multicomp as mc\n",
    "import operator as op\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from time import localtime, strftime\n",
    "import itertools\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "CODON_TYPES = ['UUU', 'UUC', 'UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG', 'AUU', 'AUC', 'AUA', 'AUG', 'GUU', 'GUC', 'GUA',\n",
    "               'GUG', 'UCU', 'UCC', 'UCA', 'UCG', 'CCU', 'CCC', 'CCA', 'CCG', 'ACU', 'ACC', 'ACA', 'ACG', 'GCU', 'GCC',\n",
    "               'GCA', 'GCG', 'UAU', 'UAC', 'CAU', 'CAC', 'CAA', 'CAG', 'AAU', 'AAC', 'AAA', 'AAG', 'GAU', 'GAC', 'GAA',\n",
    "               'GAG', 'UGU', 'UGC', 'UGG', 'CGU', 'CGC', 'CGA', 'CGG', 'AGU', 'AGC', 'AGA', 'AGG', 'GGU', 'GGC', 'GGA',\n",
    "               'GGG', 'UAA', 'UAG', 'UGA']\n",
    "\n",
    "genetic_code = {'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C',\n",
    "                'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W',\n",
    "                'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R',\n",
    "                'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R',\n",
    "                'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S',\n",
    "                'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R',\n",
    "                'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G',\n",
    "                'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}\n",
    "\n",
    "# In the following dict, synonymous codons for each amino acid are grouped in list such that they are decoded by similar tRNA.\n",
    "# For example, in amino acid 'A', GCU and GCC codons are decoded by one type of tRNA while GCA and GCG are decoded by another kind of tRNA\n",
    "synonymous = {'A': [['GCU', 'GCC'], ['GCA', 'GCG']],\n",
    "              'C': [['UGU', 'UGC']],\n",
    "              'D': [['GAU', 'GAC']],\n",
    "              'E': [['GAA'], ['GAG']],\n",
    "              'F': [['UUU', 'UUC']],\n",
    "              'G': [['GGU', 'GGC'], ['GGA'], ['GGG']],\n",
    "              'H': [['CAU', 'CAC']],\n",
    "              'I': [['AUU', 'AUC'], ['AUA']],\n",
    "              'K': [['AAG'], ['AAA']],\n",
    "              'L': [['UUG'], ['UUA'], ['CUC', 'CUU'], ['CUA', 'CUG']],\n",
    "              'M': [['AUG']],\n",
    "              'N': [['AAU', 'AAC']],\n",
    "              'P': [['CCA', 'CCG'], ['CCU', 'CCC']],\n",
    "              'Q': [['CAA'], ['CAG']],\n",
    "              'R': [['AGA'], ['CGU', 'CGC'], ['CGG', 'CGA'], ['AGG']],\n",
    "              'S': [['UCU', 'UCC'], ['AGU', 'AGC'], ['UCA'], ['UCG']],\n",
    "              'T': [['ACU', 'ACC'], ['ACA'], ['ACG']],\n",
    "              'V': [['GUU', 'GUC'], ['GUG'], ['GUA']],\n",
    "              'W': [['UGG']],\n",
    "              'Y': [['UAU', 'UAC']],\n",
    "              '*': [['UAA', 'UAG', 'UGA']]\n",
    "              }\n",
    "\n",
    "AMINO_ACIDS = ['A', 'R', 'D', 'N', 'C', 'E', 'Q', 'G', 'H', 'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V', '*']\n",
    "\n",
    "base_pairing = {'A': {'Wobble': ['GCC', 'GCG'], 'Watson-Crick': ['GCA', 'GCU']},\n",
    "                'C': {'Wobble': ['UGU'], 'Watson-Crick': ['UGC']},\n",
    "                'D': {'Wobble': ['GAU'], 'Watson-Crick': ['GAC']},\n",
    "                'E': {'Wobble': [], 'Watson-Crick': ['GAA', 'GAG']},\n",
    "                'F': {'Wobble': ['UUU'], 'Watson-Crick': ['UUC']},\n",
    "                'G': {'Wobble': ['GGU'], 'Watson-Crick': ['GGA', 'GGC', 'GGG']},\n",
    "                'H': {'Wobble': ['CAU'], 'Watson-Crick': ['CAC']},\n",
    "                'I': {'Wobble': ['AUC'], 'Watson-Crick': ['AUA', 'AUU']},\n",
    "                'K': {'Wobble': [], 'Watson-Crick': ['AAA', 'AAG']},\n",
    "                'L': {'Wobble': ['CUG', 'CUU'], 'Watson-Crick': ['CUA', 'CUC', 'UUA', 'UUG']},\n",
    "                'M': {'Wobble': [], 'Watson-Crick': ['AUG']},\n",
    "                'N': {'Wobble': ['AAU'], 'Watson-Crick': ['AAC']},\n",
    "                'P': {'Wobble': ['CCC', 'CCG'], 'Watson-Crick': ['CCA', 'CCU']},\n",
    "                'Q': {'Wobble': [], 'Watson-Crick': ['CAA', 'CAG']},\n",
    "                'R': {'Wobble': ['CGA', 'CGC'], 'Watson-Crick': ['AGA', 'AGG', 'CGG', 'CGU']},\n",
    "                'S': {'Wobble': ['UCC', 'AGU'], 'Watson-Crick': ['UCA', 'UCG', 'UCU', 'AGC']},\n",
    "                'T': {'Wobble': ['ACC'], 'Watson-Crick': ['ACA', 'ACU', 'ACG']},\n",
    "                'V': {'Wobble': ['GUC'], 'Watson-Crick': ['GUA', 'GUG', 'GUU']},\n",
    "                'W': {'Wobble': [], 'Watson-Crick': ['UGG']},\n",
    "                'Y': {'Wobble': ['UAU'], 'Watson-Crick': ['UAC']},\n",
    "                '*': {'Wobble': [], 'Watson-Crick': ['UAA', 'UAG', 'UGA']}}\n",
    "\n",
    "# Optimal codons selected based on their corresponding tRNA abundance (measured by RNA-Seq in Weinberg et al). Wobble only pairs are measured by 0.64*cognate tRNA concentration.\n",
    "# Corrected mistake for G. Earlier it was 'G': {'Non-optimal': ['GGC', 'GGG'], 'Optimal': ['GGA', 'GGU']},\n",
    "optimal_codon_usage = {'A': {'Non-optimal': ['GCC', 'GCG'], 'Optimal': ['GCA', 'GCU']},\n",
    "                       'C': {'Non-optimal': ['UGU'], 'Optimal': ['UGC']},\n",
    "                       'D': {'Non-optimal': ['GAU'], 'Optimal': ['GAC']},\n",
    "                       'E': {'Non-optimal': ['GAG'], 'Optimal': ['GAA']},\n",
    "                       'F': {'Non-optimal': ['UUU'], 'Optimal': ['UUC']},\n",
    "                       'G': {'Non-optimal': ['GGA', 'GGG'], 'Optimal': ['GGC', 'GGU']},\n",
    "                       'H': {'Non-optimal': ['CAU'], 'Optimal': ['CAC']},\n",
    "                       'I': {'Non-optimal': ['AUA'], 'Optimal': ['AUC', 'AUU']},\n",
    "                       'K': {'Non-optimal': ['AAA'], 'Optimal': ['AAG']},\n",
    "                       'L': {'Non-optimal': ['CUA', 'CUC', 'CUG', 'CUU'], 'Optimal': ['UUA', 'UUG']},\n",
    "                       'M': {'Non-optimal': [], 'Optimal': ['AUG']},\n",
    "                       'N': {'Non-optimal': ['AAU'], 'Optimal': ['AAC']},\n",
    "                       'P': {'Non-optimal': ['CCC', 'CCU'], 'Optimal': ['CCA', 'CCG']},\n",
    "                       'Q': {'Non-optimal': ['CAG'], 'Optimal': ['CAA']},\n",
    "                       'R': {'Non-optimal': ['AGG', 'CGG', 'CGA', 'CGC'], 'Optimal': ['AGA',  'CGU']},\n",
    "                       'S': {'Non-optimal': ['UCA', 'UCG', 'AGU', 'AGC'], 'Optimal': ['UCC', 'UCU']},\n",
    "                       'T': {'Non-optimal': ['ACA', 'ACG'], 'Optimal': ['ACC', 'ACU']},\n",
    "                       'V': {'Non-optimal': ['GUA', 'GUG'], 'Optimal': ['GUC', 'GUU']},\n",
    "                       'W': {'Non-optimal': [], 'Optimal': ['UGG']},\n",
    "                       'Y': {'Non-optimal': ['UAU'], 'Optimal': ['UAC']}}\n",
    "\n",
    "# Most optimal codon for every amino acid\n",
    "most_optimal_codon = {'A': 'GCU', 'C': 'UGC', 'D': 'GAC', 'E': 'GAA', 'F': 'UUC', 'G': 'GGC', 'H': 'CAC', 'I': 'AUU', 'K': 'AAG', 'L': 'UUG', 'M': 'AUG', 'N': 'AAC', 'P': 'CCA',\n",
    "                      'Q': 'CAA', 'R': 'AGA', 'S': 'UCU', 'T': 'ACU', 'V': 'GUU', 'W': 'UGG', 'Y': 'UAC', '*': 'UAA'}\n",
    "\n",
    "# Optimal and non-optimal codons based on Penchman, Frydman, tAI cutoff of 0.47 as well as used for codon optimality in Jeff Coller's paper.\n",
    "optimal_dict = {'Optimal': ['GCU', 'GCC', 'GAC', 'GAA', 'UUC', 'GGC', 'AUU', 'AUC', 'AAG', 'UUG', 'AUG', 'AAC', 'CCA', 'CAA', 'AGA', 'UCU', 'UCC', 'ACU', 'ACC', 'GUU', 'GUC', 'UAC'],\n",
    "                'Non-optimal': ['GCA', 'GCG', 'UGC', 'UGU', 'GAU', 'GAG', 'UUU', 'GGU', 'GGA', 'GGG', 'CAC', 'CAU', 'AUA', 'AAA', 'UUA', 'CUA', 'CUC', 'CUG', 'CUU', 'AAU', 'CCG',\n",
    "                                'CCU', 'CCC', 'CAG', 'CGU', 'AGG', 'CGC', 'CGG', 'CGA', 'UCA', 'AGC', 'UCG', 'AGU', 'ACA', 'ACG', 'GUG', 'GUA', 'UGG', 'UAU']}\n",
    "\n",
    "CHROMOSOMES = ['chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrVI', 'chrVII', 'chrVIII', 'chrIX', 'chrX', 'chrXI', 'chrXII', 'chrXIII', 'chrXIV', 'chrXV', 'chrXVI', 'chrM']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the python functions below that will be called to execute the data analysis for different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parse transcriptome file to get a dictionary of codon types for genes.\n",
    "def parse_sequence(transcript_file, out_loc='/gpfs/group/epo2/default/nxa176/reference/sacCer3/Reference_files/'):\n",
    "    codon_type_dict = {}\n",
    "    with open(transcript_file) as f:\n",
    "        for lines in f:\n",
    "            fields = lines.strip().split('\\t')\n",
    "            gene = fields[0]\n",
    "            if gene.startswith('Q'):\n",
    "                continue\n",
    "            start_index = int(fields[1])\n",
    "            length = int(fields[2])\n",
    "            # utr5 = list(fields[3])[:abs(start_index)]\n",
    "            cds = list(fields[3])[abs(start_index):abs(start_index)+length]\n",
    "            # Since we are looking at mRNA, convert any 'T' to 'U'\n",
    "            codon_list = ['U' if x == 'T' else x for x in cds]\n",
    "            codon_type_dict[gene] = []\n",
    "            for x in range(0, len(codon_list), 3):\n",
    "                codon_type_dict[gene].append(''.join(codon_list[x:x+3]))\n",
    "\n",
    "            # Sanitary checks for start and stop codons\n",
    "            try:\n",
    "                if codon_type_dict[gene][0] != \"AUG\":\n",
    "                    print gene + \" does not have a AUG start codon and the start codon is \" + codon_type_dict[gene][0]\n",
    "            except KeyError:\n",
    "                print 'KeyError in finding the start codon for gene ', gene, codon_type_dict[gene]\n",
    "            if codon_type_dict[gene][-1] not in [\"UAA\", \"UAG\", \"UGA\"]:\n",
    "                print gene + \" does not have UAA/UAG/UGA stop codon and stop codon is \" + codon_type_dict[gene][-1]\n",
    "\n",
    "    Pickle.dump(codon_type_dict, open(out_loc+'codon_type_dict.p', 'wb'))\n",
    "\n",
    "    return codon_type_dict\n",
    "\n",
    "\n",
    "# Parses DMS input file to determine the in vivo mRNA secondary sturcture status of indivudal nt in genes. Used when determining the prob of mol factor and controlling for it.\n",
    "def parse_dms_codon_level(dms_file):\n",
    "    dms_dict = {}\n",
    "    # Parse the DMS tab file and populate the dictionary\n",
    "    with open(dms_file) as infile:\n",
    "        infile.readline()\n",
    "        for lines in infile:\n",
    "            fields = lines.strip().split('\\t')\n",
    "            gene_name = fields[0]\n",
    "            classifier_list = map(int, fields[2].split(','))\n",
    "            dms_dict[gene_name] = classifier_list\n",
    "\n",
    "    return dms_dict\n",
    "\n",
    "\n",
    "# Parses A-site file for reads per nucleotide.\n",
    "# Converts reads per nucleotide to reads per codon.\n",
    "# Filters genes according to the criteria specified in options: genes which have at least 3 reads per codon or/and do not overlap with any other genes or/and do not have introns\n",
    "def gene_codon_filter(asite_file, mul_map_file, mul_map_threshold=1.0, filter_threshold=0.1, read_threshold=1, strict=True, window=False, relaxed=False):\n",
    "    # Total reads mapped to a gene\n",
    "    unique_mapped_reads = {}\n",
    "    # Total multiple mapped reads mapped to a gene\n",
    "    mul_mapped_reads = {}\n",
    "    # Genes with multiple mapped reads to be filtered out from analysis. Default threshold of 1%. Genes with more than 1% multiple mapped reads will be removed.\n",
    "    mul_map_genes = []\n",
    "\n",
    "    overlap_genes = Pickle.load(open('/gpfs/group/epo2/default/nxa176/Yeast_Ribo-seq_datasets/yeast_annotation_files/Pickle_dicts/overlap_genes.p', 'rb'))\n",
    "    intronic_genes = Pickle.load(open('/gpfs/group/epo2/default/nxa176/Yeast_Ribo-seq_datasets/yeast_annotation_files/Pickle_dicts/intronic_genes.p', 'rb'))\n",
    "\n",
    "    stats_file = open('Summary_stats.tab', 'w')\n",
    "\n",
    "    total_read_count = 0\n",
    "    dict_len = {}\n",
    "    codon_dict = {}\n",
    "    # Parse the A-site file to get the reads for each position of each gene\n",
    "    # We get the reads info in dict_gene_count and the nucleotide info in nuc_dict\n",
    "    with open(asite_file) as file_asite_table:\n",
    "        for lines in file_asite_table:\n",
    "            line_list = lines.strip().split('\\t')\n",
    "            gene = line_list[0]\n",
    "            gene_length = int(line_list[1])\n",
    "            count_list = map(int, line_list[2].split(','))\n",
    "            # Quality check\n",
    "            if len(count_list) % 3 != 0:\n",
    "                print 'QUALITY CHECK NOT MET: Gene '+gene+' have a length not a multiple of 3. The length is '+str(len(count_list))\n",
    "            if gene.startswith('Q'):\n",
    "                continue\n",
    "            codon_dict[gene] = []\n",
    "            # Convert the reads per nucleotide to reads per codon\n",
    "            for i in range(0, len(count_list), 3):\n",
    "                codon_dict[gene].append(sum(count_list[i:i+3]))\n",
    "            dict_len[gene] = gene_length\n",
    "            unique_mapped_reads[gene] = sum(count_list)\n",
    "            total_read_count += sum(count_list)\n",
    "\n",
    "    print 'Parsed the A-site file.'\n",
    "\n",
    "    # Get the number of mul mapped reads to decide whether to delete the gene or not. If a gene has more than 0.1% of reads multiple mapped, we delete it\n",
    "    with open(mul_map_file) as f:\n",
    "        for lines in f:\n",
    "            line_list = lines.strip().split('\\t')\n",
    "            gene = line_list[0]\n",
    "            read_count = map(int, line_list[1:])\n",
    "            mul_mapped_reads[gene] = sum(read_count)\n",
    "\n",
    "    stats_file.write('Number of genes with A-site profiles: ' + str(len(dict_len)) + '\\n')\n",
    "    stats_file.write('Number of genes containing introns: ' + str(len(intronic_genes)) + '\\n')\n",
    "    stats_file.write('Number of genes containing overlaps: ' + str(len(overlap_genes)) + '\\n')\n",
    "    stats_file.write('Number of genes containing multiple aligned reads: ' + str(len(mul_mapped_reads)) + '\\n')\n",
    "    stats_file.write('Number of reads mapped to the yeast transcriptome: ' + str(total_read_count) + '\\n')\n",
    "\n",
    "    codon_raw_file = open(\"Codon_reads_all_genes.tab\", 'w')\n",
    "    if relaxed:\n",
    "        codon_filtered_file = open(\"Codon_reads_filtered_genes_relaxed_\"+str((1-filter_threshold)*100)+\".tab\", 'w')\n",
    "    elif strict:\n",
    "        codon_filtered_file = open(\"Codon_reads_filtered_genes_strict_threshold_\" + str(read_threshold) + \".tab\", 'w')\n",
    "    else:\n",
    "        codon_filtered_file = open(\"Codon_reads_filtered_genes_window_median_greater_than_\" + str(read_threshold) + \".tab\", 'w')\n",
    "    exp_file = open(\"Expression_levels_genes.tab\", \"w\")\n",
    "    exp_file.write('Gene\\tLength(codons)\\tAverage reads (per codon)\\tSum of reads\\n')\n",
    "    codon_raw_file.write('Gene\\tLength(codons)\\tRaw read profile\\n')\n",
    "\n",
    "    # Count variables to determine the statistics of gene counts in each category\n",
    "    no_of_genes = 0\n",
    "    filtered_multistatus = 0\n",
    "    filtered_1 = 0\n",
    "    filtered_2 = 0\n",
    "    filtered_overlap = 0\n",
    "    filtered_intron = 0\n",
    "\n",
    "    for gene, gene_len in dict_len.iteritems():\n",
    "        if gene in mul_mapped_reads:\n",
    "            try:\n",
    "                perc_mul_map = float(mul_mapped_reads[gene]) * 100 / float(mul_mapped_reads[gene] + unique_mapped_reads[gene])\n",
    "            except ZeroDivisionError:\n",
    "                print 'ZeroDivisionError for mul map calculation for gene '+str(gene)\n",
    "                print mul_mapped_reads[gene], unique_mapped_reads[gene]\n",
    "                continue\n",
    "            if perc_mul_map > mul_map_threshold:\n",
    "                mul_map_genes.append(gene)\n",
    "\n",
    "        # Writing out a file at codon level\n",
    "        cod_len = len(codon_dict[gene])\n",
    "        # Sanitary check\n",
    "        if cod_len != gene_len / 3:\n",
    "            print 'Discrepancy in populating codon dicts. Length of codon dict (' + str(cod_len) + ') not equal to one-third of gene length (' + str(gene_len) + ')'\n",
    "\n",
    "        codon_raw_file.write(gene+'\\t'+str(cod_len)+'\\t' + ','.join(map(str, codon_dict[gene])) + '\\n')\n",
    "        avg_reads = np.mean(codon_dict[gene])\n",
    "        sum_reads = np.sum(codon_dict[gene])\n",
    "\n",
    "        # Select for high coverage genes based on how many positions have non-zero reads\n",
    "        number_of_zeroes = codon_dict[gene].count(0)\n",
    "\n",
    "        # By default, the threshold is 0.1 which means we will select genes which have less than 10% positions with zero reads\n",
    "        if relaxed and number_of_zeroes <= math.ceil(filter_threshold * cod_len):\n",
    "            if gene not in overlap_genes and gene not in mul_map_genes and gene not in intronic_genes:\n",
    "                if gene in mul_map_genes:\n",
    "                    filtered_multistatus += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    no_of_genes += 1\n",
    "\n",
    "                exp_file.write(gene + '\\t' + str(cod_len) + '\\t' + str(avg_reads) + '\\t' + str(sum_reads) + '\\n')\n",
    "                codon_filtered_file.write(gene + '\\t' + str(cod_len) + '\\t' + ','.join(map(str, codon_dict[gene])) + '\\n')\n",
    "\n",
    "        # If we apply the strict criteria where every codon position needs to have greater than read_threshold (default=1) reads\n",
    "        if strict:\n",
    "            # We remove the first two codons from the analysis since start codon is expected not to contain any reads and the second codon's ribosome density is influenced by initiation\n",
    "            # now each codon position should contain at least the read_threhsold number of reads for the gene to be included\n",
    "            if all(v > read_threshold for v in codon_dict[gene][2:]) and gene not in overlap_genes and gene not in intronic_genes:\n",
    "                if gene in mul_map_genes:\n",
    "                    filtered_multistatus += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    no_of_genes += 1\n",
    "\n",
    "                exp_file.write(gene+'\\t'+str(cod_len)+'\\t'+str(avg_reads)+'\\t'+str(sum_reads)+'\\n')\n",
    "                codon_filtered_file.write(gene + '\\t' + str(cod_len) + '\\t' + ','.join(map(str, codon_dict[gene])) + '\\n')\n",
    "\n",
    "            elif read_threshold >= 1 and all(v > read_threshold-1 for v in codon_dict[gene][2:]) and gene not in overlap_genes and gene not in intronic_genes and gene not in mul_map_genes:\n",
    "                filtered_2 += 1\n",
    "            elif read_threshold >= 2 and all(v > read_threshold-2 for v in codon_dict[gene][2:]) and gene not in overlap_genes and gene not in intronic_genes and gene not in mul_map_genes:\n",
    "                filtered_1 += 1\n",
    "            elif all(v > read_threshold for v in codon_dict[gene][2:]) and gene in overlap_genes and gene not in intronic_genes and gene not in mul_map_genes:\n",
    "                filtered_overlap += 1\n",
    "            elif all(v > read_threshold for v in codon_dict[gene][2:]) and gene not in overlap_genes and gene in intronic_genes:\n",
    "                filtered_intron += 1\n",
    "\n",
    "        if window:\n",
    "            # Excluding first 15 codons and last 5 codons\n",
    "            read_list = codon_dict[gene][15:-5]\n",
    "            if not read_list:\n",
    "                continue\n",
    "            window_medians = []\n",
    "            for i in range(0, len(read_list), 5):\n",
    "                # window_medians.append(np.median(read_list[i:i+5]))\n",
    "                window_medians.append(np.sum(read_list[i:i + 5]))\n",
    "            # if window_medians and all(v > read_threshold for v in window_medians):\n",
    "            if np.median(window_medians) > read_threshold:\n",
    "                if gene in mul_map_genes:\n",
    "                    filtered_multistatus += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    no_of_genes += 1\n",
    "                codon_filtered_file.write(gene + '\\t' + str(cod_len) + '\\t' + ','.join(map(str, codon_dict[gene])) + '\\n')\n",
    "\n",
    "    codon_filtered_file.close()\n",
    "\n",
    "    if relaxed:\n",
    "        print \"No. of genes which have which have greater than \" + str(filter_threshold * 100) + \"% of positions > 0: \" + str(no_of_genes)\n",
    "        stats_file.write(\"No. of genes which have which have greater than \" + str(filter_threshold * 100) + \"% of positions > 0: \" + str(no_of_genes) + '\\n')\n",
    "    if strict:\n",
    "        print \"No. of genes with atleast \" + str(read_threshold) + \" reads in each codon position is: \" + str(no_of_genes)\n",
    "        stats_file.write(\"No. of genes with greater than \" + str(read_threshold) + \" reads in each codon: \" + str(no_of_genes) + '\\n')\n",
    "        stats_file.write(\"No. of genes missed out earlier with greater than 1 reads in each codon: \" + str(filtered_1) + '\\n')\n",
    "        stats_file.write(\"No. of genes missed out earlier with greater than 0 reads in each codon: \" + str(filtered_2) + '\\n')\n",
    "        stats_file.write(\"No. of genes missed out earlier with greater than \" + str(read_threshold) + \" reads in each codon but overlapping genes: \" + str(filtered_overlap) + '\\n')\n",
    "        stats_file.write(\"No. of genes missed out earlier with greater than \" + str(read_threshold) + \" reads in each codon but intronic genes: \" + str(filtered_intron) + '\\n')\n",
    "        stats_file.write(\"No. of genes missed out earlier with greater than \" + str(read_threshold) + \" reads in each codon but contains multiple mapped reads: \" + str(\n",
    "            filtered_multistatus) + '\\n')\n",
    "    if window:\n",
    "        print \"No. of genes with atleast \" + str(read_threshold) + \" median reads in each 5 codon nonoverlapping window: \" + str(no_of_genes)\n",
    "\n",
    "    return codon_filtered_file.name\n",
    "\n",
    "\n",
    "# Convert the reads per codon of the filtered genes to translation times of codons\n",
    "def reads_to_translation_times(codon_file, genelist=''):\n",
    "    translation_times = {}\n",
    "    time_file = open(\"Translation_times_profiles.tab\", 'w')\n",
    "    #  If the translation times is to be calculated using instances from a constant set of genes, that list will be parsed here.\n",
    "    # Make sure the times_dict passed here contain info for all genes and not just for filtered genes.\n",
    "    list_of_genes = []\n",
    "    if genelist:\n",
    "        with open(genelist) as f:\n",
    "            for lines in f:\n",
    "                list_of_genes.append(lines.strip())\n",
    "        print 'Running analysis for set of '+str(len(list_of_genes))+' genes specified in file '+str(genelist)\n",
    "    # Parse the codon file to get the reads for each codon position of each gene\n",
    "    # We get the reads info in dict_gene_count and the nucleotide info in nuc_dict\n",
    "    with open(codon_file) as f:\n",
    "        for lines in f:\n",
    "            line_list = lines.strip().split('\\t')\n",
    "            gene = line_list[0]\n",
    "            if genelist and gene not in list_of_genes:\n",
    "                continue\n",
    "            count_list = map(int, line_list[2].split(','))\n",
    "            no_of_codons = len(count_list)\n",
    "            synthesis_time = no_of_codons * 200\n",
    "            # We remove the first two codons from the analysis since start codon is expected not to contain any reads and the second codon's ribosome density is influenced by initiation\n",
    "            summed_reads = sum(count_list)\n",
    "            if summed_reads == 0:\n",
    "                print gene+' does not have any mapped reads'\n",
    "                continue\n",
    "            ttime = [(float(reads) / float(summed_reads)) * synthesis_time for reads in count_list]\n",
    "            translation_times[gene] = ttime\n",
    "            time_file.write(gene + '\\t' + str(len(ttime)) + '\\t' + ','.join(map(str, ttime)) + '\\n')\n",
    "\n",
    "    time_file.close()\n",
    "    Pickle.dump(translation_times, open(\"Translation_times.p\", \"wb\"))\n",
    "\n",
    "    return translation_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the python functions that are used to compare norm ribosome density distributions and create a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-d64749e2b55e>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-d64749e2b55e>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    print '\\nRunning matrix analysis for set of '+str(len(list_of_genes))+' genes specified in file '+str(genelist)\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def psite_asite_matrix(times_dict, codon_type_dict, time=True, do_perc_change=True, genelist=''):\n",
    "    # If the Matrix is to be calculated using instances from a constant set of genes, that list will be parsed here.\n",
    "    # Make sure the times_dict passed here contain info for all genes and not just for filtered genes.\n",
    "    list_of_genes = []\n",
    "    if genelist:\n",
    "        with open(genelist) as f:\n",
    "            for lines in f:\n",
    "                list_of_genes.append(lines.strip())\n",
    "        print '\\nRunning matrix analysis for set of '+str(len(list_of_genes))+' genes specified in file '+str(genelist)\n",
    "\n",
    "    dict_amino_acids = {}\n",
    "    dict_aa_class_psite = {}\n",
    "\n",
    "    for aa in AMINO_ACIDS:\n",
    "        dict_amino_acids[aa] = []\n",
    "        dict_aa_class_psite[aa] = {}\n",
    "        for psite_aa in AMINO_ACIDS:\n",
    "            # Stop codon cannot be in P-site\n",
    "            if psite_aa == '*':\n",
    "                continue\n",
    "            dict_aa_class_psite[aa][psite_aa] = []\n",
    "\n",
    "    # We will store P-site aa for each gene and codon position in psite_aa_dict\n",
    "    psite_aa_dict = {}\n",
    "    asite_aa_dict = {}\n",
    "    log_file = open('asite_psite.log', 'w')\n",
    "    stat_measure_file = open('stat_measures.tab', 'w')\n",
    "    # Get all the aa info by translating codon_type_dict codons to corresponding amino acids\n",
    "    for gene, dict_time in times_dict.iteritems():\n",
    "        if list_of_genes and gene not in list_of_genes:\n",
    "            continue\n",
    "        psite_aa_dict[gene] = {}\n",
    "        asite_aa_dict[gene] = {}\n",
    "        for codon, trans_time in enumerate(dict_time):\n",
    "            try:\n",
    "                # Ignoring the first two codons\n",
    "                if codon in [0, 1]:\n",
    "                    continue\n",
    "                # Get the P-site aa for that codon\n",
    "                psite_aa = genetic_code[codon_type_dict[gene][codon-1]]\n",
    "                # Get the A-site aa for that codon\n",
    "                asite_aa = genetic_code[codon_type_dict[gene][codon]]\n",
    "                # dict_amino_acids will have trans time for each amino acid\n",
    "                # Ignore instances which have zero reads. This will most likely happen when we are using instances from constant set of genes which may not have necessarily met the filtering criteria.\n",
    "                if trans_time > 0:\n",
    "                    # Time based on translation time calculation. Otherwise normalized ribosome density will be used.\n",
    "                    if time:\n",
    "                        dict_amino_acids[asite_aa].append(float(trans_time))\n",
    "                    else:\n",
    "                        dict_amino_acids[asite_aa].append(float(trans_time)/200)\n",
    "                    # dict_aa_class_psite will have a dict of p-site and t-times for all a-site aa. This is a dictionary initialized before for all combo of aa\n",
    "                    # dict_aa_class_psite[Asite_AA][P-site_AA] = [trans_time, gene, A-site codon number, P-site codon type, A-site codon type]\n",
    "                    if time:\n",
    "                        dict_aa_class_psite[asite_aa][psite_aa].append((float(trans_time), gene, codon+1, codon_type_dict[gene][codon-1], codon_type_dict[gene][codon]))\n",
    "                    else:\n",
    "                        dict_aa_class_psite[asite_aa][psite_aa].append((float(trans_time)/200, gene, codon+1, codon_type_dict[gene][codon-1], codon_type_dict[gene][codon]))\n",
    "\n",
    "            except KeyError:\n",
    "                print gene, codon\n",
    "\n",
    "    # Initializing a dict for metrics to store for each pair of a-site and p-site\n",
    "    dict_aa_psite_effect_size = {}\n",
    "    dict_aa_psite_pval = {}\n",
    "    dict_aa_psite_sample_size = {}\n",
    "\n",
    "    # outf = open(\"Mean_skew_stats.tab\", 'w')\n",
    "    sig_pair_list = psite_sig_pairs('Asite_Psite_matrix_perc_change.tab')\n",
    "\n",
    "    # Initializing the inner dict for each a-site aa as key\n",
    "    for aa in AMINO_ACIDS:\n",
    "        dict_aa_psite_effect_size[aa] = {}\n",
    "        dict_aa_psite_pval[aa] = {}\n",
    "        dict_aa_psite_sample_size[aa] = {}\n",
    "\n",
    "    # For each amino acid in A-site,\n",
    "    for aa, dict_psite in dict_aa_class_psite.iteritems():\n",
    "        # for all combinations of aa in P-site and their list of trans time\n",
    "        for psite_aa, trans_list in dict_psite.iteritems():\n",
    "            times_list = []\n",
    "            # the times_list will contain only float values of translation times. trans_list contain many other values like gene name, codon number, codon type etc\n",
    "            for ttime in trans_list:\n",
    "                times_list.append(ttime[0])\n",
    "            # Create the list of trans time for all other amino acids in the P-site excluding the one being compared\n",
    "            alt_times_list = []\n",
    "            for alt_aa, list_trans in dict_psite.iteritems():\n",
    "                if alt_aa != psite_aa and alt_aa != 'P':\n",
    "                    for ttime in list_trans:\n",
    "                        alt_times_list.append(ttime[0])\n",
    "                else:\n",
    "                    continue\n",
    "            log_file.write('A-site Amino acid '+aa+'\\n')\n",
    "            log_file.write('P-site Amino acid '+psite_aa+'\\n')\n",
    "            log_file.write('Length of trans_list'+str(len(times_list))+'\\n')\n",
    "            stat_measure_file.write(psite_aa+'\\t'+aa+'\\t'+str(len(times_list))+'\\t'+str(len(alt_times_list))+'\\t'+str(np.mean(times_list))+'\\t'+str(np.mean(alt_times_list))+'\\t'+str(np.median(times_list))+'\\t' +\n",
    "                                    str(np.median(alt_times_list))+'\\t'+str(stats.skew(np.asarray(times_list)))+'\\t'+str(stats.skew(np.asarray(alt_times_list))))\n",
    "            if (psite_aa, aa) in sig_pair_list:\n",
    "                stat_measure_file.write('\\tSignificant\\n')\n",
    "            else:\n",
    "                stat_measure_file.write('\\tInsignificant\\n')\n",
    "\n",
    "            if len(times_list) >= 5:\n",
    "                u, p = stats.mannwhitneyu(times_list, alt_times_list)\n",
    "                log_file.write('Mann Whitney U test is:\\n')\n",
    "                log_file.write(str(u)+'\\t'+str(p)+'\\n')\n",
    "                if aa == 'R' and psite_aa == 'N':\n",
    "                    print 'Median(N-R)\\tMedian(Others)'\n",
    "                    print np.median(times_list), np.median(alt_times_list)\n",
    "                    # fig, ax2 = plt.subplots()\n",
    "                    # sns.distplot(times_list, ax=ax2, kde=True, label=psite_aa + '_' + aa)\n",
    "                    # sns.distplot(times_list_new, ax=ax2, kde=True, label=psite_new + '_' + aa)\n",
    "                    # N = max(max(set(times_list)), max(set(alt_times_list)))\n",
    "                    Pickle.dump(times_list, open(aa + '_' + psite_aa + '_instances.p', 'wb'))\n",
    "                    Pickle.dump(alt_times_list, open(aa + 'not'+psite_aa+'_instances.p', 'wb'))\n",
    "                Pickle.dump(times_list, open('pickle_dicts/' + aa + '_' + psite_aa + '_instances.p', 'wb'))\n",
    "                Pickle.dump(alt_times_list, open('pickle_dicts/' + aa + '_~' + psite_aa + '_instances.p', 'wb'))\n",
    "                perc_change = ((np.median(times_list) - np.median(alt_times_list))/np.median(alt_times_list))*100\n",
    "                perc_diff = ((np.median(times_list) - np.median(alt_times_list)) / ((np.median(times_list)+np.median(alt_times_list))/2)) * 100\n",
    "                # Mostly use perc change as you want to know how much X in P-site causes slowdown/speedup in X-Y pair relative to when X is not present\n",
    "                if do_perc_change:\n",
    "                    dict_aa_psite_effect_size[aa][psite_aa] = perc_change\n",
    "                else:\n",
    "                    # Use perc_diff when you are comparing two specific AA pairs X-Y and Z-Y\n",
    "                    dict_aa_psite_effect_size[aa][psite_aa] = perc_diff\n",
    "                dict_aa_psite_pval[aa][psite_aa] = p\n",
    "                dict_aa_psite_sample_size[aa][psite_aa] = [len(times_list), len(alt_times_list)]\n",
    "                # outf.write(psite_aa+'\\t'+aa+'\\t'+str(np.mean(times_list))+'\\t'+str(np.median(times_list))+'\\t'+str(stats.skew(times_list)))\n",
    "            else:\n",
    "                dict_aa_psite_effect_size[aa][psite_aa] = 0  # 'Sample_less_than_5'\n",
    "                dict_aa_psite_pval[aa][psite_aa] = 1  # 'Sample_less_than_5'\n",
    "                dict_aa_psite_sample_size[aa][psite_aa] = [len(times_list), len(alt_times_list)]\n",
    "\n",
    "    times_file = open(\"Asite_Psite_times_coordinates.tab\", \"w\")\n",
    "    times_file.write(\"Asite\\tPsite\\tTranslation_time_Asite_codon\\tGene\\tAsite_codon_number\\tPsite_codon\\tAsite_codon\\n\")\n",
    "    for aa, dict_psite in dict_aa_class_psite.iteritems():\n",
    "        for psite, trans_list in dict_psite.iteritems():\n",
    "            for codon in sorted(trans_list, reverse=True):\n",
    "                times_file.write(aa+'\\t'+psite+'\\t'+str(codon[0])+'\\t'+str(codon[1])+'\\t'+str(codon[2])+'\\t'+str(codon[3])+'\\t'+codon[4]+'\\n')\n",
    "    times_file.close()\n",
    "\n",
    "    if do_perc_change:\n",
    "        outf = open('Asite_Psite_matrix_perc_change.tab', 'w')\n",
    "    else:\n",
    "        outf = open('Asite_Psite_matrix_perc_diff.tab', 'w')\n",
    "\n",
    "    # Benjamini-Hochberg correction. We get all the p-values and pool them together in a list and adjust it\n",
    "    list_of_pval = []\n",
    "    for aa, data in sorted(dict_aa_psite_effect_size.iteritems()):\n",
    "        for p_site in sorted(data):\n",
    "            if dict_aa_psite_pval[aa][p_site] == 2:\n",
    "                continue\n",
    "            else:\n",
    "                list_of_pval.append(dict_aa_psite_pval[aa][p_site])\n",
    "    hyp_test, pval_adj, alpsidac, alpbonf = mc.multipletests(list_of_pval, method='fdr_bh')   # bonferonni\n",
    "\n",
    "    dict_aa_psite_pval_adj = {}\n",
    "    outf.write('A-site AA\\tP-site AA\\tPercent change\\tp-value\\tAdjusted p-value\\tN(P-A pair)\\t(Alt P-A pair)\\n')\n",
    "    # Extract back the adjusted p-values into corresponding cells making sure that the keys are sorted according to when it was put in the list for multiple test correction\n",
    "    i = 0\n",
    "    for aa, data in sorted(dict_aa_psite_effect_size.iteritems()):\n",
    "        dict_aa_psite_pval_adj[aa] = {}\n",
    "        for p_site, perc_change in sorted(data.iteritems()):\n",
    "            if dict_aa_psite_pval[aa][p_site] == 2:\n",
    "                dict_aa_psite_pval_adj[aa][p_site] = 1\n",
    "            else:\n",
    "                dict_aa_psite_pval_adj[aa][p_site] = pval_adj[i]\n",
    "                i += 1\n",
    "            outf.write(aa+'\\t'+p_site+'\\t'+str(perc_change)+'%\\t'+str(dict_aa_psite_pval[aa][p_site])+'\\t'+str(dict_aa_psite_pval_adj[aa][p_site])+'\\t' +\n",
    "                       str(dict_aa_psite_sample_size[aa][p_site][0]) + '\\t'+str(dict_aa_psite_sample_size[aa][p_site][1])+'\\n')\n",
    "\n",
    "    return dict_aa_psite_effect_size, dict_aa_psite_pval_adj, dict_aa_class_psite\n",
    "\n",
    "\n",
    "def parse_psite_matrix_info(matrix_file):\n",
    "    dict_pairs = {}\n",
    "    dict_perc_change = {}\n",
    "    dict_pval = {}\n",
    "    # Parse the matrix file and get the percent change, pvalue and sample size information\n",
    "    with open(matrix_file) as f:\n",
    "        # Skip the header\n",
    "        f.next()\n",
    "        for lines in f:\n",
    "            fields = lines.strip().split('\\t')\n",
    "            aa_pair = fields[1] + fields[0]\n",
    "            perc = float(fields[2].split('%')[0])\n",
    "            adj_p_val = float(fields[4])\n",
    "            samp_size = int(fields[5])\n",
    "            compared_size = int(fields[6])\n",
    "            dict_pairs[aa_pair] = [perc, adj_p_val, samp_size, compared_size]\n",
    "            if fields[0] not in dict_perc_change:\n",
    "                dict_perc_change[fields[0]] = {}\n",
    "                dict_pval[fields[0]] = {}\n",
    "            dict_perc_change[fields[0]][fields[1]] = perc\n",
    "            dict_pval[fields[0]][fields[1]] = adj_p_val\n",
    "\n",
    "    return dict_pairs, dict_perc_change, dict_pval\n",
    "\n",
    "\n",
    "def measure_robustness_of_pairs(dict_of_pairs, datsets, threshold=4, control_factor='', compare_uncontrolled='', condition=''):\n",
    "    pair_stats = {}\n",
    "    # Populating a dict with all the statistics\n",
    "    for data_set in datsets:\n",
    "        for pair in dict_of_pairs[data_set]:\n",
    "            if pair not in pair_stats:\n",
    "                pair_stats[pair] = {'perc': [], 'adj_pval': [], 'samp_size': [], 'other_size': []}\n",
    "            pair_stats[pair]['perc'].append(dict_of_pairs[data_set][pair][0])\n",
    "            pair_stats[pair]['adj_pval'].append(dict_of_pairs[data_set][pair][1])\n",
    "            pair_stats[pair]['samp_size'].append(dict_of_pairs[data_set][pair][2])\n",
    "            pair_stats[pair]['other_size'].append(dict_of_pairs[data_set][pair][3])\n",
    "\n",
    "    if control_factor:\n",
    "        outfile = open('Merged_pair_statistics_'+control_factor+condition+'.tab', 'w')\n",
    "        statfile = open('Control_factor_stats_'+control_factor+'.tab', 'w')\n",
    "    else:\n",
    "        outfile = open('Merged_pairs_statistics'+condition+'.tab', 'w')\n",
    "        statfile = open('Control_factor_stats_' + condition + '.tab', 'w')\n",
    "    # Putting all the stats together for all datasets\n",
    "    for pair in pair_stats:\n",
    "        outfile.write(pair + '\\t' + '\\t'.join(map(str, pair_stats[pair]['perc'])) + '\\t' + '\\t'.join(map(str, pair_stats[pair]['adj_pval']))\n",
    "                      + '\\t' + '\\t'.join(map(str, pair_stats[pair]['samp_size'])) + '\\t' + '\\t'.join(map(str, pair_stats[pair]['other_size'])) + '\\n')\n",
    "\n",
    "    robust_pairs = {'Fast': [], 'Slow': [], 'Mixed': [], 'Not Robust': []}\n",
    "    dict_robust_perc = {}\n",
    "    dict_robust_pval = {}\n",
    "\n",
    "    for pair in pair_stats:\n",
    "        if pair[1] not in dict_robust_perc:\n",
    "            dict_robust_perc[pair[1]] = {}\n",
    "            dict_robust_pval[pair[1]] = {}\n",
    "        percs = pair_stats[pair]['perc']\n",
    "        pvals = pair_stats[pair]['adj_pval']\n",
    "        counter = 0\n",
    "        for pval in pvals:\n",
    "            if pval < 0.05:\n",
    "                counter += 1\n",
    "        # The threshold is the number of datasets in which there should be a significant change in speed.\n",
    "        if counter >= threshold:\n",
    "            # All the pairs should show translational speed change in the same direction to be considered robust\n",
    "            if all(p > 0 for p in percs):\n",
    "                robust_pairs['Slow'].append(pair)\n",
    "                dict_robust_perc[pair[1]][pair[0]] = np.mean(percs)\n",
    "                # Assigning a constant pvalue of 0 for significant pairs.\n",
    "                dict_robust_pval[pair[1]][pair[0]] = 0\n",
    "            elif all(p < 0 for p in percs):\n",
    "                robust_pairs['Fast'].append(pair)\n",
    "                dict_robust_perc[pair[1]][pair[0]] = np.mean(percs)\n",
    "                # Assigning a constant pvalue of 0 for significant pairs.\n",
    "                dict_robust_pval[pair[1]][pair[0]] = 0\n",
    "            else:\n",
    "                # Determine the trend in data\n",
    "                # if at least the 'threshold' number of datasets show same direction\n",
    "                if sum(p > 0 for p in percs) >= threshold:\n",
    "                    updated_percs = []\n",
    "                    for idx, val in enumerate(pvals):\n",
    "                        if val < 0.05:\n",
    "                            updated_percs.append(percs[idx])\n",
    "                elif sum(p < 0 for p in percs) >= threshold:\n",
    "                    updated_percs = []\n",
    "                    for idx, val in enumerate(pvals):\n",
    "                        if val < 0.05:\n",
    "                            updated_percs.append(percs[idx])\n",
    "                else:\n",
    "                    updated_percs = percs\n",
    "                # in addition to condition in above comment, if all significant data sets show same direction\n",
    "                if all(p > 0 for p in updated_percs):\n",
    "                    robust_pairs['Slow'].append(pair)\n",
    "                    dict_robust_perc[pair[1]][pair[0]] = np.mean(percs)\n",
    "                    # Assigning a constant p-value of 0 for significant pairs.\n",
    "                    dict_robust_pval[pair[1]][pair[0]] = 0\n",
    "                elif all(p < 0 for p in updated_percs):\n",
    "                    robust_pairs['Fast'].append(pair)\n",
    "                    dict_robust_perc[pair[1]][pair[0]] = np.mean(percs)\n",
    "                    # Assigning a constant p-value of 0 for significant pairs.\n",
    "                    dict_robust_pval[pair[1]][pair[0]] = 0\n",
    "                else:\n",
    "                    robust_pairs['Mixed'].append(pair)\n",
    "                    dict_robust_perc[pair[1]][pair[0]] = np.mean(percs)\n",
    "                    # Assigning a constant p-value of 0.5 for insignificant pairs.\n",
    "                    dict_robust_pval[pair[1]][pair[0]] = 0.5\n",
    "        else:\n",
    "            robust_pairs['Not Robust'].append(pair)\n",
    "            dict_robust_perc[pair[1]][pair[0]] = np.mean(percs)\n",
    "            # Assigning a constant p-value of 0.5 for insignificant pairs.\n",
    "            dict_robust_pval[pair[1]][pair[0]] = 0.5\n",
    "    if control_factor:\n",
    "        outf = open('Robust_aminoacid_pairs_' + control_factor+'_'+str(threshold) + condition + '_datasets.tab', 'w')\n",
    "    else:\n",
    "        outf = open('Robust_aminoacid_pairs_'+str(threshold)+condition+'_datasets.tab', 'w')\n",
    "    outf.write('Pair\\tPair_type\\tAvg(Perc change)')\n",
    "    for data_set in datsets:\n",
    "        outf.write('\\t Perc change('+str(data_set)+')')\n",
    "    outf.write('\\t')\n",
    "    for data_set in datsets:\n",
    "        outf.write('\\t p-value('+str(data_set)+')')\n",
    "    outf.write('\\n')\n",
    "    for pair_type in robust_pairs:\n",
    "        for pair in robust_pairs[pair_type]:\n",
    "            outf.write(pair + '\\t' + pair_type + '\\t' + str(np.mean(pair_stats[pair]['perc'])) + '\\t' + '\\t'.join(map(str, pair_stats[pair]['perc'])) + '\\t' +\n",
    "                       '\\t'.join(map(str, pair_stats[pair]['adj_pval'])) + '\\n')\n",
    "\n",
    "    print 'Length of the dict robust perc is '+str(len(dict_robust_perc))\n",
    "    print 'Length of the dict robust pvalue is '+str(len(dict_robust_pval))\n",
    "\n",
    "    if compare_uncontrolled:\n",
    "        fast_consistent = 0\n",
    "        slow_consistent = 0\n",
    "        fast_insignificant = 0\n",
    "        slow_insignificant = 0\n",
    "        inconsistent = 0\n",
    "        with open(compare_uncontrolled) as f:\n",
    "            f.next()\n",
    "            for lines in f:\n",
    "                fields = lines.strip().split('\\t')\n",
    "                pair = fields[0]\n",
    "                pair_type = fields[1]\n",
    "                if pair_type == 'Fast' and pair in robust_pairs[pair_type]:\n",
    "                    fast_consistent += 1\n",
    "                elif pair_type == 'Fast' and pair not in robust_pairs[pair_type]:\n",
    "                    fast_insignificant += 1\n",
    "                elif pair_type == 'Slow' and pair in robust_pairs[pair_type]:\n",
    "                    slow_consistent += 1\n",
    "                elif pair_type == 'Slow' and pair not in robust_pairs[pair_type]:\n",
    "                    slow_insignificant += 1\n",
    "                else:\n",
    "                    inconsistent += 1\n",
    "                    if pair_type == 'Fast' and pair in robust_pairs['Slow']:\n",
    "                        print pair + ' is Slow when controlled for '+control_factor+' but fast when not controlled'\n",
    "                    elif pair_type == 'Slow' and pair in robust_pairs['Fast']:\n",
    "                        print pair + ' is Fast when controlled for '+control_factor+' but slow when not controlled'\n",
    "\n",
    "        perc_cons = float(fast_consistent) * 100 / float(fast_consistent + fast_insignificant)\n",
    "        perc_cons_slow = float(slow_consistent) * 100 / float(slow_consistent + slow_insignificant)\n",
    "        print 'Control factor\\tConsistent\\tInconsistent\\n'\n",
    "        print control_factor, fast_consistent, fast_insignificant, perc_cons, slow_consistent, slow_insignificant, perc_cons_slow, inconsistent\n",
    "        statfile.write(str(control_factor)+'\\t'+str(fast_consistent)+'\\t'+str(fast_insignificant)+'\\t'+str(perc_cons)+'\\t'+str(slow_consistent)+'\\t'+str(slow_insignificant)+'\\t'+\n",
    "                       str(perc_cons_slow)+'\\t'+str(inconsistent))\n",
    "    # if control_factor != 'Not controlled for any factors':\n",
    "    #     matrix_plot, legend_plot = plot_asite_psite_matrix(dict_robust_perc, dict_robust_pval, control_factor+' % Consistent with uncontrolled='+str(round(perc_cons,1))+'%', title_fontsize=12)\n",
    "    # else:\n",
    "    matrix_plot, legend_plot = plot_asite_psite_matrix(dict_robust_perc, dict_robust_pval, control_factor)\n",
    "    # ppdf = pdf.PdfPages('Asite_Psite_plot_for_robust_pairs_'+str(threshold)+'_datasets.pdf')\n",
    "    # ppdf.savefig(matrix_plot)\n",
    "    # ppdf.savefig(legend_plot)\n",
    "    # ppdf.close()\n",
    "    return matrix_plot, dict_robust_perc, dict_robust_pval\n",
    "\n",
    "\n",
    "# PLOT THE MATRIX FIGURE 1B\n",
    "def plot_asite_psite_matrix(dict_asite_psite_metric, dict_asite_psite_adj_pval, title, txt=False, title_fontsize=18):\n",
    "    # Open stats file to append the matrix stats\n",
    "    stats_file = open('Summary_stats.tab', 'a')\n",
    "    stats_file.write('\\n\\nSTATISTICS FOR AMINO ACIDS PAIRS\\n')\n",
    "    # Converting the dict of dicts into list of lists to be converted to a numpy matrix\n",
    "    # One empty list is added for the '*' codon which needs to appear in the first row before Y, W etc\n",
    "    list_of_lists = [[]]\n",
    "    list_of_pval_adj = [[]]\n",
    "    for aa, data in sorted(dict_asite_psite_metric.items(), reverse=True):\n",
    "        psite_list = []\n",
    "        psite_pval_adj_list = []\n",
    "        for p_site, perc_change in sorted(data.iteritems()):\n",
    "            try:\n",
    "                if p_site == '*':\n",
    "                    continue\n",
    "                psite_list.append(perc_change)\n",
    "                psite_pval_adj_list.append(dict_asite_psite_adj_pval[aa][p_site])\n",
    "            except KeyError:\n",
    "                psite_list.append(0)\n",
    "                psite_pval_adj_list.append(1)\n",
    "        if aa == '*':\n",
    "            list_of_lists[0] = psite_list\n",
    "            list_of_pval_adj[0] = psite_pval_adj_list\n",
    "        else:\n",
    "            list_of_lists.append(psite_list)\n",
    "            list_of_pval_adj.append(psite_pval_adj_list)\n",
    "\n",
    "    # print 'Length of list_of_lists', 'Length of list of pval adj'\n",
    "    # print len(list_of_lists), len(list_of_pval_adj)\n",
    "    # print list_of_pval_adj\n",
    "    ap_matrix = np.array(list_of_lists)\n",
    "    ap_matrix_pval = np.array(list_of_pval_adj)\n",
    "    # print 'Matrix shape ',ap_matrix.shape\n",
    "    # print 'P-val matrix shape ',ap_matrix_pval.shape\n",
    "    '''\n",
    "    np.savetxt('Asite_P-site_matrix.tab', ap_matrix, delimiter='\\t')\n",
    "\n",
    "    row_labels = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y',\n",
    "                  '*']\n",
    "    col_labels = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y',\n",
    "                  '*']\n",
    "\n",
    "    plt.matshow(ap_matrix)\n",
    "    plt.xticks(range(21), col_labels)\n",
    "    plt.yticks(range(21), row_labels)\n",
    "\n",
    "    plt.savefig(title+.'png')\n",
    "    '''\n",
    "    # print ap_matrix\n",
    "    ap_matrix_new = pd.DataFrame(ap_matrix, index=['*', 'Y', 'W', 'V', 'T', 'S', 'R', 'Q', 'P', 'N', 'M', 'L', 'K', 'I', 'H', 'G', 'F', 'E', 'D', 'C', 'A'],\n",
    "                                 columns=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I',  'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T',  'V', 'W', 'Y'])\n",
    "\n",
    "    figure, pairs_stats = checkerboard_table(ap_matrix_new, ap_matrix_pval, txt=txt)\n",
    "    plt.xlabel('P-site Amino Acid', fontsize=18)\n",
    "    plt.ylabel('A-site Amino Acid', fontsize=18)\n",
    "    figure2 = generate_legend_for_matrix()\n",
    "    figure.suptitle(title, fontsize=title_fontsize)\n",
    "\n",
    "    figure.savefig('Matrix.png', dpi=300)\n",
    "    stats_file.write('Total number of amino acid pairs: '+str(pairs_stats['total_pairs'])+'\\n')\n",
    "    stats_file.write('Total number of fast amino acid pairs: ' + str(pairs_stats['fast_sig_pair']) + '\\n')\n",
    "    stats_file.write('Total number of slow amino acid pairs: ' + str(pairs_stats['slow_sig_pair']) + '\\n')\n",
    "    stats_file.write('Total number of insignificant amino acid pairs: '+str(pairs_stats['insig_pair'])+'\\n')\n",
    "    stats_file.write('Total number of amino acid pairs with less than 5 instances: ' + str(pairs_stats['insufficient']) + '\\n')\n",
    "    stats_file.close()\n",
    "    return figure, figure2\n",
    "\n",
    "\n",
    "def checkerboard_table(data, pval, fmt='{:.2f}', txt=False, xlabel='P-site Amino Acid', ylabel='A-site Amino Acid'):\n",
    "    pairs_stats = {'total_pairs': 0, 'fast_sig_pair': 0, 'slow_sig_pair': 0, 'insig_pair': 0, 'insufficient': 0}\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # ax.set_axis_off()\n",
    "    fig.savefig('Original.png')\n",
    "    # ax.set_axis_off()\n",
    "\n",
    "    plt.setp(ax.spines.values(), visible=False)\n",
    "    # ax.tick_params(left=True, labelleft=True, labelbottom=True, bottom=True, direction='out', length=4, width=1)\n",
    "    ax.tick_params(left=False, labelleft=False, labelbottom=False, bottom=False, direction='out', length=4, width=1)\n",
    "    # ax.set_xticks(range(0, 20))\n",
    "    # ax.set_yticks(range(0, 21))\n",
    "    # ax.set_xticklabels(data.columns)\n",
    "    # ax.set_yticklabels(data.index)\n",
    "    # ax.patch.set_visible(False)\n",
    "    # ax.set_frame_on(False)\n",
    "    ax.grid(False)\n",
    "    # ax.xaxis.set_visible(False)\n",
    "    # ax.yaxis.set_visible(False)\n",
    "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
    "    mpl.rcParams['grid.linewidth'] = 0.5\n",
    "    nrows, ncols = data.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "    # Add cells\n",
    "    for (i, j), val in np.ndenumerate(data):\n",
    "        pairs_stats['total_pairs'] += 1\n",
    "        # Index either the first or second item of bkg_colors based on\n",
    "        # a checker board pattern\n",
    "        if pval[i][j] < 0.05:\n",
    "            if val < 0:\n",
    "                pairs_stats['fast_sig_pair'] += 1\n",
    "            else:\n",
    "                pairs_stats['slow_sig_pair'] += 1\n",
    "            if val < -50:\n",
    "                color = 'blue'\n",
    "            elif val < -25:\n",
    "                color = 'green'\n",
    "            elif val < -10:\n",
    "                color = 'mediumseagreen'     # darkcyan\n",
    "            elif val < 0:\n",
    "                color = 'lightgreen'   # cyan\n",
    "            elif val > 100:\n",
    "                # color = 'red'\n",
    "                color = 'maroon'\n",
    "            elif val > 75:\n",
    "                # color = 'darkorange'  red\n",
    "                color = 'red'\n",
    "            elif val > 50:\n",
    "                color = 'tomato'  # darkorange\n",
    "            elif val > 25:\n",
    "                color = 'orange'\n",
    "            elif val > 0:\n",
    "                color = 'gold'   # yellow\n",
    "            else:\n",
    "                color = 'grey'\n",
    "        elif pval[i][j] == 1:\n",
    "            color = 'grey'\n",
    "            pairs_stats['insufficient'] += 1\n",
    "        else:\n",
    "            color = 'silver'  # lightgrey\n",
    "            pairs_stats['insig_pair'] += 1\n",
    "        if txt:\n",
    "            tb.add_cell(i, j, width, width, text=fmt.format(val), loc='center', facecolor=color)\n",
    "        else:\n",
    "            tb.add_cell(i, j, width, width, loc='center', facecolor=color)\n",
    "    for key, cell in tb.get_celld().items():\n",
    "        cell.set_linewidth(0.5)\n",
    "    # Row Labels...\n",
    "    for i, label in enumerate(data.index):\n",
    "        tb.add_cell(i, -1, width, width, text=label, loc='right', edgecolor='none', facecolor='none')\n",
    "    # Column Labels...\n",
    "    for j, label in enumerate(data.columns):\n",
    "        tb.add_cell(22, j, width, width, text=label, loc='center', edgecolor='none', facecolor='none',)\n",
    "    tb.set_fontsize(8)\n",
    "    ax.add_table(tb)\n",
    "    ax.set_xlabel(xlabel, fontsize=16)\n",
    "    ax.set_ylabel(ylabel, fontsize=16)\n",
    "    ax.yaxis.set_label_coords(-0.05, 0.5)\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "    # ax.legend(loc='upper left', frameon=False)\n",
    "\n",
    "    return fig, pairs_stats\n",
    "\n",
    "\n",
    "def generate_legend_for_matrix():\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.savefig('Original.png')\n",
    "    # ax.set_axis_off()\n",
    "    ax.set_xlabel('P-site Amino Acid', fontsize=18)\n",
    "    ax.set_ylabel('A-site Amino Acid', fontsize=18)\n",
    "    ax.yaxis.set_label_coords(-0.05, 0.5)\n",
    "    plt.setp(ax.spines.values(), visible=False)\n",
    "    # ax.tick_params(left=True, labelleft=True, labelbottom=True, bottom=True, direction='out', length=4, width=1)\n",
    "    ax.tick_params(left=False, labelleft=False, labelbottom=False, bottom=False, direction='out', length=4, width=1)\n",
    "    # ax.set_xticks(range(0, 20))\n",
    "    # ax.set_yticks(range(0, 21))\n",
    "    # ax.set_xticklabels(data.columns)\n",
    "    # ax.set_yticklabels(data.index)\n",
    "    ax.patch.set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    ax.grid(False)\n",
    "    # ax.xaxis.set_visible(False)\n",
    "    # ax.yaxis.set_visible(False)\n",
    "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
    "\n",
    "    data = np.array([[-55, 0, 0, 0, -20, 0, 0, 0, 8, 0, 0, 0, 60, 0, 0, 0, 103, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [-44, 0, 0, 0, -8, 0, 0, 0, 30, 0, 0, 0, 80, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [-20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [-8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [30, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [60, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [80, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [103, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "                     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "    pval = np.array([[0.01, 1, 1, 1, 0.01, 1, 1, 1, 0.01, 1, 1, 1, 0.01, 1, 1, 1, 0.01, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 0.01, 1, 1, 1, 0.01, 1, 1, 1, 0.01, 1, 1, 1, 2, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [0.01, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                     [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "    nrows, ncols = data.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / ncols\n",
    "    # Add cells\n",
    "    for (i, j), val in np.ndenumerate(data):\n",
    "        # Index either the first or second item of bkg_colors based on\n",
    "        # a checker board pattern\n",
    "        if pval[i][j] < 0.05:\n",
    "            if val < -50:\n",
    "                color = 'blue'\n",
    "            elif val < -25:\n",
    "                color = 'green'\n",
    "            elif val < -10:\n",
    "                color = 'mediumseagreen'     # darkcyan\n",
    "            elif val < 0:\n",
    "                color = 'lightgreen'   # cyan\n",
    "            elif val > 100:\n",
    "                # color = 'red'\n",
    "                color = 'maroon'\n",
    "            elif val > 75:\n",
    "                # color = 'darkorange'  red\n",
    "                color = 'red'\n",
    "            elif val > 50:\n",
    "                color = 'tomato'  # darkorange\n",
    "            elif val > 25:\n",
    "                color = 'orange'\n",
    "            elif val > 0:\n",
    "                color = 'gold'   # yellow\n",
    "            else:\n",
    "                color = 'white'\n",
    "        elif pval[i][j] == 1:\n",
    "            color = 'white'\n",
    "\n",
    "        else:\n",
    "            color = 'silver'  # lightgrey\n",
    "        # if pval[i][j] < 0.05:\n",
    "        #     if val < -50:\n",
    "        #         color = 'blue'\n",
    "        #     elif val < -25:\n",
    "        #         color = 'green'\n",
    "        #     elif val < -10:\n",
    "        #         color = 'darkcyan'\n",
    "        #     elif val < 0:\n",
    "        #         color = 'cyan'\n",
    "        #     elif val > 100:\n",
    "        #         # color = 'red'\n",
    "        #         color = 'darkred'\n",
    "        #     elif val > 75:\n",
    "        #         # color = 'darkorange'\n",
    "        #         color = 'red'\n",
    "        #     elif val > 50:\n",
    "        #         color = 'darkorange'\n",
    "        #     elif val > 25:\n",
    "        #         color = 'orange'\n",
    "        #     elif val > 0:\n",
    "        #         color = 'yellow'\n",
    "        #\n",
    "        # elif pval[i][j] == 1:\n",
    "        #     color = 'white'\n",
    "        #\n",
    "        # elif pval[i][j] == 2:\n",
    "        #     color = 'lightgrey'\n",
    "        # elif pval[i][j] == 3:\n",
    "        #     color = 'grey'\n",
    "\n",
    "        if color == 'white':\n",
    "            tb.add_cell(i, j, width, width, edgecolor=color, loc='center', facecolor=color)\n",
    "        else:\n",
    "            tb.add_cell(i, j, width, width, loc='center', facecolor=color, edgecolor=color)\n",
    "\n",
    "    # # Row Labels...\n",
    "    # for i, label in enumerate(data.index):\n",
    "    #     tb.add_cell(i, -1, width, width, text=label, loc='right',\n",
    "    #                 edgecolor='none', facecolor='none')\n",
    "    # # Column Labels...\n",
    "    # for j, label in enumerate(data.columns):\n",
    "    #     tb.add_cell(22, j, width, width, text=label, loc='center',\n",
    "    #                 edgecolor='none', facecolor='none', )\n",
    "    tb.set_fontsize(14)\n",
    "    ax.add_table(tb)\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1 - x0) / abs(y1 - y0))\n",
    "    # ax.legend(loc='upper left', frameon=False)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# R2 response for more stats related to skew of the distributions\n",
    "def psite_sig_pairs(infile):\n",
    "    sig_pairs_list = []\n",
    "    with open(infile) as f:\n",
    "        f.next()\n",
    "        for lines in f:\n",
    "            fields = lines.strip().split('\\t')\n",
    "            psite_aa = fields[1]\n",
    "            asite_aa = fields[0]\n",
    "            adj_pvalue = float(fields[4])\n",
    "            if adj_pvalue < 0.05:\n",
    "                sig_pairs_list.append((psite_aa, asite_aa))\n",
    "    return sig_pairs_list\n",
    "\n",
    "\n",
    "# PLOT THE MATRIX subplot for all 6 datasets  (FIGURE S1)\n",
    "def plot_figS1_subplot_matrix_datasets(dict_plots):\n",
    "    # Creating a figure object\n",
    "    fig = plt.figure(figsize=(5, 7))\n",
    "\n",
    "    # Reducing the distance by half (default is 6) between the title and the subplot\n",
    "    rcParams['axes.titlepad'] = 3\n",
    "\n",
    "    ax1 = fig.add_subplot(321)\n",
    "    ap_matrix, ap_matrix_pval = get_matrix_dataframe(dict_plots['Williams'][0], dict_plots['Williams'][1])\n",
    "\n",
    "    ax1, pairs_stats = checkerboard_table_subplot(ap_matrix, ap_matrix_pval, ax=ax1, xlabel=False)\n",
    "    ax1.tick_params(width=1, length=4, axis='both', which='major', labelsize=6, pad=2)\n",
    "    ax1.set_title('Williams', fontsize=8)\n",
    "    ax1.text(-0.12 * ax1.get_xlim()[1], 1.025 * ax1.get_ylim()[1], 'a', fontsize=10, fontweight='bold')\n",
    "\n",
    "    ax2 = fig.add_subplot(322)\n",
    "    ap_matrix, ap_matrix_pval = get_matrix_dataframe(dict_plots['Jan'][0], dict_plots['Jan'][1])\n",
    "\n",
    "    ax2, pairs_stats = checkerboard_table_subplot(ap_matrix, ap_matrix_pval, ax=ax2, xlabel=False)  # Having ylabel for all subplots to avoid dead space, ylabel=False)\n",
    "    ax2.tick_params(width=1, length=4, axis='both', which='major', labelsize=6, pad=2)\n",
    "    ax2.set_title('Jan', fontsize=8)\n",
    "    ax2.text(-0.1225 * ax2.get_xlim()[1], 1.0125 * ax2.get_ylim()[1], 'b', fontsize=10, fontweight='bold')\n",
    "\n",
    "    ax3 = fig.add_subplot(323, adjustable='box-forced')\n",
    "    ap_matrix, ap_matrix_pval = get_matrix_dataframe(dict_plots['Nissley1'][0], dict_plots['Nissley1'][1])\n",
    "\n",
    "    ax3, pairs_stats = checkerboard_table_subplot(ap_matrix, ap_matrix_pval, ax=ax3, xlabel=False)\n",
    "    ax3.tick_params(width=1, length=4, axis='both', which='major', labelsize=6, pad=2)\n",
    "    ax3.set_title('Nissley Replicate 1', fontsize=8)\n",
    "    ax3.text(-0.12 * ax3.get_xlim()[1], 1.0275 * ax3.get_ylim()[1], 'c', fontsize=10, fontweight='bold')\n",
    "\n",
    "    ax4 = fig.add_subplot(324)\n",
    "    ap_matrix, ap_matrix_pval = get_matrix_dataframe(dict_plots['Nissley2'][0], dict_plots['Nissley2'][1])\n",
    "\n",
    "    ax4, pairs_stats = checkerboard_table_subplot(ap_matrix, ap_matrix_pval, ax=ax4, xlabel=False)  # , ylabel=False)\n",
    "    ax4.tick_params(width=1, length=4, axis='both', which='major', labelsize=6, pad=2)\n",
    "    ax4.set_title('Nissley Replicate 2', fontsize=8)\n",
    "    ax4.text(-0.12 * ax4.get_xlim()[1], 1.015 * ax4.get_ylim()[1], 'd', fontsize=10, fontweight='bold')\n",
    "\n",
    "    ax5 = fig.add_subplot(325)\n",
    "    ap_matrix, ap_matrix_pval = get_matrix_dataframe(dict_plots['Weinberg'][0], dict_plots['Weinberg'][1])\n",
    "\n",
    "    ax5, pairs_stats = checkerboard_table_subplot(ap_matrix, ap_matrix_pval, ax=ax5)\n",
    "    ax5.tick_params(width=1, length=4, axis='both', which='major', labelsize=6, pad=2)\n",
    "    ax5.set_title('Weinberg', fontsize=8)\n",
    "    ax5.text(-0.12 * ax5.get_xlim()[1], 1.025 * ax5.get_ylim()[1], 'e', fontsize=10, fontweight='bold')\n",
    "\n",
    "    ax6 = fig.add_subplot(326)\n",
    "    ap_matrix, ap_matrix_pval = get_matrix_dataframe(dict_plots['Young'][0], dict_plots['Young'][1])\n",
    "\n",
    "    ax6, pairs_stats = checkerboard_table_subplot(ap_matrix, ap_matrix_pval, ax=ax6)  # , ylabel=False)\n",
    "    ax6.tick_params(width=1, length=4, axis='both', which='major', labelsize=6, pad=2)\n",
    "    ax6.set_title('Young', fontsize=8)\n",
    "    ax6.text(-0.12 * ax6.get_xlim()[1], 1.0135 * ax6.get_ylim()[1], 'f', fontsize=10, fontweight='bold')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.savefig('FigureS1.png', dpi=600, pad_inches=0)\n",
    "\n",
    "\n",
    "def checkerboard_table_subplot(data, pval, ax, xlabel_txt='P-site Amino Acid', ylabel_txt='A-site Amino Acid', xlabel=True, ylabel=True):\n",
    "    pairs_stats = {'total_pairs': 0, 'fast_sig_pair': 0, 'slow_sig_pair': 0, 'insig_pair': 0, 'insufficient': 0}\n",
    "\n",
    "    plt.setp(ax.spines.values(), visible=False)\n",
    "    # ax.tick_params(left=True, labelleft=True, labelbottom=True, bottom=True, direction='out', length=4, width=1)\n",
    "    ax.tick_params(left=False, labelleft=False, labelbottom=False, bottom=False, direction='out', length=4, width=1)\n",
    "    # ax.set_xticks(range(0, 20))\n",
    "    # ax.set_yticks(range(0, 21))\n",
    "    # ax.set_xticklabels(data.columns)\n",
    "    # ax.set_yticklabels(data.index)\n",
    "    # ax.patch.set_visible(False)\n",
    "    # ax.set_frame_on(False)\n",
    "    ax.grid(False)\n",
    "    # ax.xaxis.set_visible(False)\n",
    "    # ax.yaxis.set_visible(False)\n",
    "    tb = Table(ax, bbox=[0, 0, 1, 1])\n",
    "    mpl.rcParams['grid.linewidth'] = 0.5\n",
    "    nrows, ncols = data.shape\n",
    "    width, height = 1.0 / ncols, 1.0 / nrows\n",
    "    # Add cells\n",
    "    for (i, j), val in np.ndenumerate(data):\n",
    "        pairs_stats['total_pairs'] += 1\n",
    "        # Index either the first or second item of bkg_colors based on\n",
    "        # a checker board pattern\n",
    "        if pval[i][j] < 0.05:\n",
    "            if val < 0:\n",
    "                pairs_stats['fast_sig_pair'] += 1\n",
    "            else:\n",
    "                pairs_stats['slow_sig_pair'] += 1\n",
    "            if val < -50:\n",
    "                color = 'blue'\n",
    "            elif val < -25:\n",
    "                color = 'green'\n",
    "            elif val < -10:\n",
    "                color = 'mediumseagreen'     # darkcyan\n",
    "            elif val < 0:\n",
    "                color = 'lightgreen'   # cyan\n",
    "            elif val > 100:\n",
    "                # color = 'red'\n",
    "                color = 'maroon'\n",
    "            elif val > 75:\n",
    "                # color = 'darkorange'  red\n",
    "                color = 'red'\n",
    "            elif val > 50:\n",
    "                color = 'tomato'  # darkorange\n",
    "            elif val > 25:\n",
    "                color = 'orange'\n",
    "            elif val > 0:\n",
    "                color = 'gold'   # yellow\n",
    "            else:\n",
    "                color = 'grey'\n",
    "        elif pval[i][j] == 1:\n",
    "            color = 'grey'\n",
    "            pairs_stats['insufficient'] += 1\n",
    "        else:\n",
    "            color = 'silver'  # lightgrey\n",
    "            pairs_stats['insig_pair'] += 1\n",
    "\n",
    "        tb.add_cell(i, j, width, width, loc='center', facecolor=color)\n",
    "    for key, cell in tb.get_celld().items():\n",
    "        cell.set_linewidth(0.5)\n",
    "    # Row Labels...\n",
    "    for i, label in enumerate(data.index):\n",
    "        tb.add_cell(i, -1, width, width, text=label, loc='right', edgecolor='none', facecolor='none')\n",
    "    # Column Labels...\n",
    "    for j, label in enumerate(data.columns):\n",
    "        tb.add_cell(22, j, width, width, text=label, loc='left', edgecolor='none', facecolor='none',)\n",
    "    tb.set_fontsize(8)\n",
    "    ax.add_table(tb)\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel_txt, fontsize=8)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel_txt, fontsize=8)\n",
    "    ax.yaxis.set_label_coords(-0.05, 0.5)\n",
    "    x0, x1 = ax.get_xlim()\n",
    "    y0, y1 = ax.get_ylim()\n",
    "    ax.set_aspect(abs(x1-x0)/abs(y1-y0))\n",
    "    # ax.legend(loc='upper left', frameon=False)\n",
    "\n",
    "    return ax, pairs_stats\n",
    "\n",
    "\n",
    "def compare_individual_aa_pairs(dict_aa_psite, min_dist_length=5, perc_diff=True, plot_perc=True):\n",
    "    # Open stats file to append the stats for comparison\n",
    "    stats_file = open('Summary_stats.tab', 'a')\n",
    "\n",
    "    if not os.path.exists('pickle_dicts/'):\n",
    "        os.makedirs('pickle_dicts/')\n",
    "\n",
    "    # The effect size of the diff between two dist can be measured either as a percent difference or percent change.\n",
    "    # For comparing two amino acid pairs, it is not proper to choose one as a reference. Hence most likely we will measure a percent difference between them\n",
    "    if perc_diff:\n",
    "        outf = open('Asite_Psite_perc_diff_new_Psite.tab', 'w')\n",
    "        log_file = open('asite_psite_perc_difference.log', 'w')\n",
    "    else:\n",
    "        outf = open('Asite_Psite_perc_change_new_Psite.tab', 'w')\n",
    "        log_file = open('asite_psite_perc_change.log', 'w')\n",
    "\n",
    "    # Initializing a dict for metrics to store for each pair of A-site and P-site\n",
    "    dict_effect_size = {}\n",
    "    dict_pvalues = {}\n",
    "    dict_times_list = {}\n",
    "\n",
    "    palette_colors = [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725), (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),\n",
    "                      (0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "    sns.set()\n",
    "    sns.set_palette(palette_colors)\n",
    "\n",
    "    # Initializing the inner dict for each A-site aa as key\n",
    "    for aa in AMINO_ACIDS:\n",
    "        dict_effect_size[aa] = {}\n",
    "        dict_pvalues[aa] = {}\n",
    "        for psite in AMINO_ACIDS:\n",
    "            # Stop codon cannot be in P-site\n",
    "            if psite != '*':\n",
    "                dict_effect_size[aa][psite] = {}\n",
    "                dict_pvalues[aa][psite] = {}\n",
    "    for aa, dict_psite in dict_aa_psite.iteritems():\n",
    "        # For aa in A-site\n",
    "        dict_times_list[aa] = {}\n",
    "        # for P-site aa and list of translation times and other details\n",
    "        for psite_aa, trans_list in dict_psite.iteritems():\n",
    "            # Ignoring an impossible case\n",
    "            if psite_aa == '*':\n",
    "                continue\n",
    "            # trans_list is a list of all values for each instance of trans time of the format [trans_time, gene, codon number, P-site codon type, A-site codon type]\n",
    "            times_list = []\n",
    "            # the times_list will contain only float values of translation times\n",
    "            for ttime in trans_list:\n",
    "                times_list.append(ttime[0])\n",
    "            log_file.write('A-site Amino acid '+aa+'\\n')\n",
    "            log_file.write('P-site Amino acid '+psite_aa+'\\n')\n",
    "            log_file.write('Length of trans_list'+str(len(times_list))+'\\n')\n",
    "\n",
    "            dict_times_list[aa][psite_aa] = times_list\n",
    "            if len(times_list) >= min_dist_length:\n",
    "                # for all other combinations of P-site aa with this A-site aa, we will calculate the % difference\n",
    "                for psite_new, trans_list_new in dict_psite.iteritems():\n",
    "                    if psite_aa != psite_new and psite_new != '*':\n",
    "                        times_list_new = []\n",
    "                        for trans_time in trans_list_new:\n",
    "                            times_list_new.append(trans_time[0])\n",
    "                        # Compare the distributions and calculate the percentage difference between the medians\n",
    "                        if len(times_list_new) >= 5:\n",
    "                            u, p = stats.mannwhitneyu(times_list, times_list_new)\n",
    "\n",
    "                            # Printing out test cases which are the mutated samples and also plotting their distributions\n",
    "                            if (aa, psite_aa, psite_new) in [('R', 'N', 'S'), ('Q', 'W', 'D'), ('T', 'W', 'D'), ('T', 'M', 'G')]:\n",
    "                                # The plot for ('R', 'N', 'S') is used for Fig 1B\n",
    "                                print 'Median('+psite_aa+'-'+aa+')\\tMedian('+psite_new+'-'+aa+')'\n",
    "                                print np.median(times_list), np.median(times_list_new)\n",
    "                                Pickle.dump(times_list, open('pickle_dicts/'+aa+'_'+psite_aa+'_instances.p', 'wb'))\n",
    "                                Pickle.dump(times_list_new, open('pickle_dicts/'+aa+'_'+psite_new+'_instances.p', 'wb'))\n",
    "                                plot_trans_distribution(aa, psite_aa, psite_new, 'pickle_dicts/')\n",
    "\n",
    "                            # Variance of the distributions\n",
    "                            var_orig = np.var(times_list)\n",
    "                            var_mut = np.var(times_list_new)\n",
    "\n",
    "                            log_file.write('Mann Whitney U test with '+psite_new+' in the P-site and '+aa+' in the A-site is:\\n')\n",
    "                            log_file.write(str(u)+'\\t'+str(p)+'\\n')\n",
    "\n",
    "                            # Choosing the effect size\n",
    "                            if perc_diff:\n",
    "                                effect_size = math.fabs(np.median(times_list_new) - np.median(times_list))*100/((np.median(times_list)+np.median(times_list_new))/2)\n",
    "                            else:\n",
    "                                effect_size = ((np.median(times_list_new) - np.median(times_list)) / np.median(times_list)) * 100\n",
    "\n",
    "                            # The odds of getting the speed change in the same direction as the difference of the medians.\n",
    "                            odds = odds_speed_change_aa(times_list, times_list_new)\n",
    "\n",
    "                            if odds == -1:\n",
    "                                print 'Zero division error for odds for comparison of '+psite_aa+'_'+aa+' with '+psite_new+'_'+aa\n",
    "\n",
    "                            # This dict is storing for every pair of P-site-Asite, when P-site is mutated to new P-site, what is the perc change in trans time of the medians\n",
    "                            dict_effect_size[aa][psite_aa][psite_new] = [effect_size, len(times_list), len(times_list_new), var_orig, var_mut, odds]\n",
    "                            dict_pvalues[aa][psite_aa][psite_new] = p\n",
    "\n",
    "                        else:\n",
    "                            var_orig = np.var(times_list)\n",
    "                            var_mut = np.var(times_list_new)\n",
    "                            odds = odds_speed_change_aa(times_list, times_list_new)\n",
    "                            if odds == -1:\n",
    "                                print 'Zero division error for odds for comparison of '+psite_aa+'_'+aa+' with '+psite_new+'_'+aa+'. Sample size of new psite is less than 5'\n",
    "                            dict_effect_size[aa][psite_aa][psite_new] = [0, len(times_list), len(times_list_new), var_orig, var_mut, odds]  # 'Sample_less_than_5'\n",
    "                            dict_pvalues[aa][psite_aa][psite_new] = 2  # 'Sample_less_than_5'\n",
    "            else:\n",
    "                for psite_new, trans_list_new in dict_psite.iteritems():\n",
    "                    if psite_new != psite_aa and psite_new != '*':\n",
    "                        times_list_new = []\n",
    "                        for trans_time in trans_list_new:\n",
    "                            times_list_new.append(trans_time[0])\n",
    "                        var_orig = np.var(times_list)\n",
    "                        var_mut = np.var(times_list_new)\n",
    "                        odds = odds_speed_change_aa(times_list, times_list_new)\n",
    "                        if odds == -1:\n",
    "                            print 'Zero division error for odds for comparison of ' + psite_aa + '_' + aa + ' with ' + psite_new + '_' + aa + '. Sample size of old psite is less than 5'\n",
    "                        dict_effect_size[aa][psite_aa][psite_new] = [0, len(times_list), len(times_list_new), var_orig, var_mut, odds]  # 'Sample_less_than_5'\n",
    "                        dict_pvalues[aa][psite_aa][psite_new] = 2  # 'Sample_less_than_5'\n",
    "\n",
    "    # Benjamini-Hochberg correction. We get all the p-values and pool them together in a list and adjust it\n",
    "    list_of_pval = []\n",
    "    for aa, data in sorted(dict_effect_size.iteritems()):\n",
    "        for p_site, data_lower in sorted(data.iteritems()):\n",
    "            for psite_new in sorted(data_lower):\n",
    "                if dict_pvalues[aa][p_site][psite_new] == 2:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_of_pval.append(dict_pvalues[aa][p_site][psite_new])\n",
    "\n",
    "    hyp_test, pval_adj, alpsidac, alpbonf = mc.multipletests(list_of_pval, method='fdr_bh')\n",
    "\n",
    "    dict_aa_psite_pval_adj = {}\n",
    "    pairs_stats = {'total_pairs': 0, 'fast_sig_pair': 0, 'slow_sig_pair': 0, 'insig_pair': 0, 'insufficient': 0}\n",
    "    candidates = [['G', 'P', 'E'], ['T', 'G', 'S'], ['G', 'G', 'S'], ['R', 'N', 'S'], ['G', 'D', 'F'], ['R', 'S', 'N'], ['T', 'S', 'G'], ['G', 'S', 'G'], ['D', 'Q', 'P'], ['D', 'E', 'P']]\n",
    "\n",
    "    odds_list = []\n",
    "    odds_list_insig = []\n",
    "    outf.write('A-site\\tP-site\\tNew P-site\\tPercent Difference\\tOdds\\tInstances(P-site)\\tInstances(New P-site)\\tVariance(P-site)\\tVariance(New P-site)\\tp-value\\t'\n",
    "               'adjusted p-value\\tSignificance\\n')\n",
    "    # Extract back the adjusted p-values into corresponding cells\n",
    "    i = 0\n",
    "    print 'Writing output file for P-site new psite comparisons'\n",
    "    for aa, data in sorted(dict_effect_size.iteritems()):\n",
    "        dict_aa_psite_pval_adj[aa] = {}\n",
    "        for p_site, data_lower in sorted(data.iteritems()):\n",
    "            dict_aa_psite_pval_adj[aa][p_site] = {}\n",
    "            for psite_new, data_under in sorted(data_lower.iteritems()):\n",
    "                effect_size, len_orig, len_mut, var_orig, var_mut, odds = data_under\n",
    "                pairs_stats['total_pairs'] += 1\n",
    "                if dict_pvalues[aa][p_site][psite_new] == 2:\n",
    "                    dict_aa_psite_pval_adj[aa][p_site][psite_new] = 1\n",
    "                    pairs_stats['insufficient'] += 1\n",
    "                    odds_list_insig.append(odds)\n",
    "                    significance = 'Not Significant'\n",
    "                else:\n",
    "                    dict_aa_psite_pval_adj[aa][p_site][psite_new] = pval_adj[i]\n",
    "                    i += 1\n",
    "                    if dict_aa_psite_pval_adj[aa][p_site][psite_new] > 0.05:\n",
    "                        pairs_stats['insig_pair'] += 1\n",
    "                        odds_list_insig.append(odds)\n",
    "                        significance = 'Not Significant'\n",
    "                    else:\n",
    "                        significance = 'Significant'\n",
    "                        if effect_size < 0:\n",
    "                            pairs_stats['fast_sig_pair'] += 1\n",
    "                        else:\n",
    "                            pairs_stats['slow_sig_pair'] += 1\n",
    "                            odds_list.append(odds)\n",
    "                    aa_pair = [aa, p_site, psite_new]\n",
    "                    if aa_pair in candidates:\n",
    "                        stats_file.write(aa+'\\t'+p_site+'\\t'+psite_new+'\\t'+str(effect_size)+'%\\t'+str(dict_pvalues[aa][p_site][psite_new])+'\\t'+str(dict_aa_psite_pval_adj[aa][p_site][psite_new]) + '\\n')\n",
    "                outf.write(aa+'\\t'+p_site+'\\t'+psite_new+'\\t'+str(effect_size)+'%\\t'+str(odds)+'\\t'+str(len_orig)+'\\t'+str(len_mut)+'\\t'+str(var_orig)+'\\t'+str(var_mut)+'\\t' +\n",
    "                           str(dict_pvalues[aa][p_site][psite_new])+'\\t'+str(dict_aa_psite_pval_adj[aa][p_site][psite_new]) + '\\t' + significance + '\\n')\n",
    "    outf.close()\n",
    "    # Plot the odds of translation speed change for pairs of amino acids. This plot is used for Fig 1D\n",
    "    fig, ax3 = plt.subplots()\n",
    "    binsize = np.arange(0, 8, 0.25)\n",
    "    ax3 = sns.distplot(sorted(odds_list)[:-10], ax=ax3, kde=False, label=\"Significant pairs\", norm_hist=True, bins=binsize, hist_kws=dict(edgecolor=\"black\", linewidth=1))\n",
    "    # If we also have to plot the odds for the insignificant pairs\n",
    "    # ax3 = sns.distplot(sorted(odds_list_insig)[:-10], ax=ax3, kde=True, label=\"Insignificant pairs\", norm_hist=True, bins=binsize, hist_kws=dict(edgecolor=\"black\", linewidth=1))\n",
    "    # ax3.legend(fontsize=20).set_visible(False)\n",
    "    ax3.tick_params(direction='out', axis='both', width=1, length=4, which='major', labelsize=16, pad=2, bottom=True, left=True)\n",
    "    ax3.set_xlabel('Odds of translation rate change', fontsize=16)\n",
    "    ax3.set_ylabel('Probability Density', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig('Odds_of_speed_change_significant.png', dpi=300)\n",
    "\n",
    "    if plot_perc:\n",
    "        plot_perc_change_aa('Asite_Psite_perc_diff_new_Psite.tab', perc_diff=perc_diff)\n",
    "\n",
    "    stats_file.write('\\n\\nSTATISTICS FOR CHANGE IN TRNASLATION SPEED BETWEEN AMINO ACIDS PAIRS\\n')\n",
    "    stats_file.write('Total number of amino acid mutation pairs: ' + str(pairs_stats['total_pairs']) + '\\n')\n",
    "    stats_file.write('Total number of fast amino acid mutating pairs: ' + str(pairs_stats['fast_sig_pair']) + '\\n')\n",
    "    stats_file.write('Total number of slow amino acid mutating pairs: ' + str(pairs_stats['slow_sig_pair']) + '\\n')\n",
    "    stats_file.write('Total number of insignificant amino acid mutating  pairs: ' + str(pairs_stats['insig_pair']) + '\\n')\n",
    "    stats_file.write('Total number of amino acid mutating pairs with less than 5 instances: ' + str(pairs_stats['insufficient']) + '\\n')\n",
    "    stats_file.close()\n",
    "\n",
    "\n",
    "# Plotting the normalized ribosome density distributions for two pairs of amino acids\n",
    "def plot_trans_distribution(aa, psite_aa, psite_new, infolder, plot_both=True):\n",
    "    palette_colors = [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725), (0.3333333333333333, 0.6588235294117647, 0.40784313725490196)]\n",
    "    # (0.8666666666666667, 0.5176470588235295, 0.3215686274509804)]\n",
    "    plt.style.use('seaborn-white')\n",
    "    sns.set_palette(palette_colors)\n",
    "    times_list = Pickle.load(open(infolder+aa+'_'+psite_aa+'_instances.p', 'rb'))\n",
    "    times_list_new = Pickle.load(open(infolder+aa+'_'+psite_new+'_instances.p', 'rb'))\n",
    "\n",
    "    # plt.style.use('seaborn-white')\n",
    "    fig, ax2 = plt.subplots()\n",
    "    # sns.distplot(times_list, ax=ax2, kde=True, label=psite_aa + '_' + aa)\n",
    "    # sns.distplot(times_list_new, ax=ax2, kde=True, label=psite_new + '_' + aa)\n",
    "    N = max(max(set(times_list)), max(set(sorted(times_list_new)[:-10])))\n",
    "    # Pickle.dump(times_list, open('R_N_instances.p', 'wb'))\n",
    "    # Pickle.dump(times_list_new, open('R_S_instances.p', 'wb'))\n",
    "    binsize = np.arange(0, N + 1, 0.25)\n",
    "    # ax2 = sns.distplot(times_list, ax=ax2, kde=True, norm_hist=True, hist=False,label=None, bins=binsize, hist_kws=dict(edgecolor=\"black\", linewidth=1))\n",
    "    # ax2 = sns.distplot(times_list_new, ax=ax2, kde=True, norm_hist=True, hist=False,label=None, bins=binsize, hist_kws=dict(edgecolor=\"black\", linewidth=1))\n",
    "    ax2 = sns.distplot(times_list, ax=ax2, kde=True, norm_hist=True, label='{'+psite_aa + '-' + aa+'}', bins=binsize, hist_kws=dict(edgecolor=\"black\", linewidth=1))\n",
    "    print 'Plotting trans distributions with changes'\n",
    "    # If plot an overlap of the distribution of the second pair of amino acid.\n",
    "    if plot_both:\n",
    "        ax2 = sns.distplot(times_list_new, ax=ax2, kde=True, norm_hist=True, label='{'+psite_new + '-' + aa+'}', bins=binsize, hist_kws=dict(edgecolor=\"black\", linewidth=1))\n",
    "    # ax2.set_ylim(0,1.02)\n",
    "    ax2.set_xlim(-0.8, 7)\n",
    "    ax2.legend(fontsize=16, loc='upper right')\n",
    "    # labels = np.arange(ax2.get_ylim()[0]*0.25, ax2.get_ylim()[1]*0.25)\n",
    "    # ylabel_list = list(ax2.get_yticklabels())\n",
    "    # print ylabel_list\n",
    "    # ax2.set_yticklabels(labels)\n",
    "    ax2.tick_params(direction='out', axis='both', width=1, length=4, which='major', labelsize=16, pad=2)\n",
    "    ax2.set_xlabel('Normalized Ribosome Density', fontsize=16)\n",
    "    ax2.set_ylabel('Density', fontsize=16)\n",
    "    if plot_both:\n",
    "        fig.savefig(aa + '_' + psite_aa + '_' + psite_new + '.png', bbox_inches='tight', dpi=300)\n",
    "    else:\n",
    "        fig.savefig(aa + '_' + psite_aa + '.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "def plot_perc_change_aa(perc_file, perc_diff=True, outf='Perc_difference_of_P-site.png', compare_with_uncontrolled=False, white=False):\n",
    "    plot_data = pd.read_table(perc_file)\n",
    "    fig, ax1 = plt.subplots()\n",
    "    if white:\n",
    "        plt.style.use('seaborn-white')\n",
    "    else:\n",
    "        sns.set()\n",
    "    palette_colors = [(0.2980392156862745, 0.4470588235294118, 0.6901960784313725), (0.8666666666666667, 0.5176470588235295, 0.3215686274509804),\n",
    "                      (0.5490196078431373, 0.5490196078431373, 0.5490196078431373)]\n",
    "    # green (0.3333333333333333, 0.6588235294117647, 0.40784313725490196),]\n",
    "    # plt.style.use('seaborn-white')\n",
    "    sns.set_palette(palette_colors)\n",
    "    # ax1 = plt.subplot2grid(shape=(4, 20), loc=(0, 0), colspan=4, rowspan=2)\n",
    "    # ax1.set(yscale='log')\n",
    "    list_perc_change = [float(x.split('%')[0]) for x in plot_data['Percent Difference']]\n",
    "    list_pvals = [-np.log(val) for val in plot_data['adjusted p-value']]\n",
    "    if compare_with_uncontrolled:\n",
    "        list_sig = list(plot_data['Comparison with uncontrolled'])\n",
    "        for idx, val in enumerate(list_sig):\n",
    "            if val == '(Insufficient sample size) Not Significant after controlling for confounding factors':\n",
    "                list_sig[idx] = 'Not Significant after filtering out Wobble decoding pairs'\n",
    "            elif val == 'Not Significant after controlling for confounding factor':\n",
    "                list_sig[idx] = 'Not Significant after filtering out Wobble decoding pairs'\n",
    "        order_hue = ['Significant', 'Not Significant', 'Not Significant after filtering out Wobble decoding pairs']\n",
    "    else:\n",
    "        list_sig = list(plot_data['Significance'])\n",
    "        order_hue = ['Significant', 'Not Significant']\n",
    "    # mapping = {'Significant' : 'blue', 'Not-significant' : 'red'}\n",
    "    print len(list_perc_change), len(list_pvals), len(list_sig)\n",
    "    ax1 = sns.scatterplot(list_perc_change, list_pvals, hue=list_sig, hue_order=order_hue, ax=ax1, s=5, linewidth=0.05)  # , hue_order=['Significant', 'Not-significant'])\n",
    "    # ax1.set_title('FAST', fontsize=16)\n",
    "    ax1.set_ylabel('-log (p-value)', fontsize=14)\n",
    "    if perc_diff:\n",
    "        #  % difference in translation rate\n",
    "        ax1.set_xlabel('% difference in median ' + r'$\\rho$', fontsize=14)\n",
    "    else:\n",
    "        ax1.set_xlabel('% change in translation rate', fontsize=14)\n",
    "    # ax1.xaxis.label.set_visible(False)\n",
    "    ax1.tick_params(width=1, length=4, axis='x', which='major', labelsize=9, pad=2, direction='out', bottom=True)\n",
    "    ax1.tick_params(width=1, length=2, axis='y', which='major', labelsize=9, pad=1, direction='out', left=True)\n",
    "    ax1.axhline(y=2.9957, linestyle='--', color='black')\n",
    "    ax1.legend(fontsize=10, loc='upper left')\n",
    "    ax1.xaxis.set_ticks(np.arange(0, 145, 10))\n",
    "    ax1.yaxis.set_ticks(np.arange(0, 121, 20))\n",
    "    # ax1.xaxis.set_ticks(np.arange(math.floor(ax1.get_xlim()[0]), math.ceil(ax1.get_xlim()[1]), 10))\n",
    "    fig.savefig(outf, dpi=300)\n",
    "\n",
    "\n",
    "def odds_speed_change_aa(times1, times2):\n",
    "    list_diff = []\n",
    "    for time1 in times1:\n",
    "        for time2 in times2:\n",
    "            diff = time2-time1\n",
    "            list_diff.append(diff)\n",
    "    perc_change = ((np.median(times2) - np.median(times1)) / np.median(times1)) * 100\n",
    "    if perc_change > 0:\n",
    "        try:\n",
    "            odds = float(sum(i > 0 for i in list_diff))/float(sum(i < 0 for i in list_diff))\n",
    "        except ZeroDivisionError:\n",
    "            odds = -1\n",
    "    else:\n",
    "        try:\n",
    "            odds = float(sum(i < 0 for i in list_diff))/float(sum(i > 0 for i in list_diff))\n",
    "        except ZeroDivisionError:\n",
    "            odds = -1\n",
    "    return odds\n",
    "\n",
    "\n",
    "def bin_norm_dens_plot_aa_psite_freq(times_dict, sig_pairs_file, codon_type_dict):\n",
    "    sig_pairs = []\n",
    "    with open(sig_pairs_file) as s:\n",
    "        for lines in s:\n",
    "            fields = lines.strip().split('\\t')\n",
    "            pair = fields[0]\n",
    "            status = fields[1]\n",
    "            if status in ['Fast', 'Slow']:\n",
    "                sig_pairs.append(pair)\n",
    "\n",
    "    dict_amino_acids = {}\n",
    "    dict_aa_class_psite = {}\n",
    "\n",
    "    for aa in AMINO_ACIDS:\n",
    "        dict_amino_acids[aa] = []\n",
    "        dict_aa_class_psite[aa] = {}\n",
    "        for psite_aa in AMINO_ACIDS:\n",
    "            # Stop codon cannot be in P-site\n",
    "            if psite_aa == '*':\n",
    "                continue\n",
    "            dict_aa_class_psite[aa][psite_aa] = []\n",
    "\n",
    "    # We will store P-site aa for each gene and codon position in psite_aa_dict\n",
    "    psite_aa_dict = {}\n",
    "    asite_aa_dict = {}\n",
    "\n",
    "    total_sig_norm_dens = []\n",
    "    total_aa_dist = []\n",
    "    # Get all the aa info by translating codon_type_dict codons to corresponding amino acids\n",
    "    for gene, dict_time in times_dict.iteritems():\n",
    "        psite_aa_dict[gene] = {}\n",
    "        asite_aa_dict[gene] = {}\n",
    "        for codon, trans_time in enumerate(dict_time):\n",
    "            try:\n",
    "                # Ignoring the first two codons\n",
    "                if codon in [0, 1]:\n",
    "                    continue\n",
    "                # Get the P-site aa for that codon\n",
    "                psite_aa = genetic_code[codon_type_dict[gene][codon - 1]]\n",
    "                # Get the A-site aa for that codon\n",
    "                asite_aa = genetic_code[codon_type_dict[gene][codon]]\n",
    "                # dict_amino_acids will have trans time for each amino acid\n",
    "                # Ignore instances which have zero reads. This will most likely happen when we are using instances from constant set of genes which may not have necessarily met the filtering criteria.\n",
    "                if trans_time > 0:\n",
    "                    # Time based on translation time calculation. Otherwise normalized ribosome density will be used.\n",
    "                    dict_amino_acids[asite_aa].append(float(trans_time) / 200)\n",
    "                    # dict_aa_class_psite will have a dict of p-site and t-times for all a-site aa. This is a dictionary initialized before for all combo of aa\n",
    "                    # dict_aa_class_psite[Asite_AA][P-site_AA] = [trans_time, gene, A-site codon number, P-site codon type, A-site codon type]\n",
    "                    dict_aa_class_psite[asite_aa][psite_aa].append((float(trans_time) / 200, gene, codon + 1, codon_type_dict[gene][codon - 1], codon_type_dict[gene][codon]))\n",
    "                    # if psite_aa+asite_aa in sig_pairs:\n",
    "                    total_sig_norm_dens.append(float(trans_time) / 200)\n",
    "                    total_aa_dist.append(psite_aa)\n",
    "            except KeyError:\n",
    "                print gene, codon\n",
    "\n",
    "    total_sig_norm_dens_array = np.asarray(total_sig_norm_dens)\n",
    "    percentile_dict = {}\n",
    "    psite_bin = {}\n",
    "    for i in range(0, 110, 10):\n",
    "        percentile_dict[i] = np.percentile(total_sig_norm_dens_array, i)\n",
    "        if i < 100:\n",
    "            psite_bin[str(i)+'-'+str(i+10)] = []\n",
    "\n",
    "    # for pair in sig_pairs:\n",
    "    #     psite_aa = pair[0]\n",
    "    #     asite_aa = pair[1]\n",
    "    for asite_aa in AMINO_ACIDS:\n",
    "        for psite_aa in AMINO_ACIDS:\n",
    "            if psite_aa == '*':\n",
    "                continue\n",
    "            for val in dict_aa_class_psite[asite_aa][psite_aa]:\n",
    "                for i in range(0, 100, 10):\n",
    "                    if percentile_dict[i] <= val[0] < percentile_dict[i+10]:\n",
    "                        psite_bin[str(i)+'-'+str(i+10)].append(psite_aa)\n",
    "\n",
    "    print 'Length of psite_bin is '+str(len(psite_bin))\n",
    "    if len(psite_bin) < 30:\n",
    "        print 'Psite bin contains the following keys: '+str(psite_bin.keys())\n",
    "\n",
    "    outf = open(\"Percentile_ranges_Psite_aa_frequencies.tab\", \"w\")\n",
    "    for perc_range in psite_bin:\n",
    "        for psite_aa in set(psite_bin[perc_range]):\n",
    "            psite_freq = psite_bin[perc_range].count(psite_aa)*100/len(psite_bin[perc_range])\n",
    "            outf.write(perc_range+'\\t'+str(psite_aa)+'\\t'+str(psite_freq)+'\\n')\n",
    "\n",
    "    outf.close()\n",
    "\n",
    "    aa_prob = open('Total_AA_prob_across_gene_subset.tab', 'w')\n",
    "    for aa in AMINO_ACIDS:\n",
    "        if aa == '*':\n",
    "            continue\n",
    "        aa_freq = total_aa_dist.count(aa)*100/len(total_aa_dist)\n",
    "        aa_prob.write(aa+'\\t'+str(aa_freq)+'\\n')\n",
    "    aa_prob.close()\n",
    "\n",
    "\n",
    "def plot_lineplot(infile, prob_file):\n",
    "    dict_prob = {}\n",
    "    with open(prob_file) as f:\n",
    "        for lines in f:\n",
    "            fields = lines.strip().split('\\t')\n",
    "            dict_prob[fields[0]] = float(fields[1])\n",
    "    full_data = pd.read_table(infile, sep='\\t')\n",
    "    plot_data = full_data[full_data['AA'].isin(['P', 'N', 'D', 'S', 'V', 'E'])]\n",
    "    plt.figure()\n",
    "    palette_vals = sns.color_palette()\n",
    "    ax = sns.lineplot(x='Perc_range', y='freq', data=plot_data, hue='AA', hue_order=['S', 'V', 'E', 'D', 'N', 'P'], style='AA', dashes=False, markers=True)\n",
    "    ax.set_xlabel('Percentile range', fontsize=7)\n",
    "    ax.set_ylabel('Frequency (%)', fontsize=7)\n",
    "    # ax2.yaxis.label.set_visible(False)\n",
    "    ax.tick_params(width=1, length=4, axis='x', which='major', labelsize=6, left=True, bottom=True)\n",
    "    # ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    ax.tick_params(width=1, length=4, axis='y', which='major', labelsize=6, pad=2)\n",
    "    ax.axhline(dict_prob['S'], color=palette_vals[0], linestyle='-')\n",
    "    ax.axhline(dict_prob['V'], color=palette_vals[1], linestyle='-')\n",
    "    ax.axhline(dict_prob['E'], color=palette_vals[2], linestyle='-')\n",
    "    ax.axhline(dict_prob['D'], color=palette_vals[3], linestyle='-')\n",
    "    ax.axhline(dict_prob['N'], color=palette_vals[4], linestyle='-')\n",
    "    ax.axhline(dict_prob['P'], color=palette_vals[5], linestyle='-')\n",
    "    plt.xticks(rotation=45)\n",
    "    # Shrink current axis by 20%\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # Put a legend to the right of the current axis\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # ax.legend().set_visible(True)\n",
    "    plt.savefig('Binned_plot_AA_freq.png', bbox_inches='tight', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
